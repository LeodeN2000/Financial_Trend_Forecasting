{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b315f3c-ae60-475d-8233-edcbeeaa69ee",
   "metadata": {},
   "source": [
    "# Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2278adb-9214-417e-a02e-54cdd24a208e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0. Imports & Basic formating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f650ae-24bc-4b2b-9f2c-b97a98812a5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3af210-5758-4885-ba83-c77aad92cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "from keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import F1Score\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779cb5d3-0fff-43df-9397-ce92a041493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    df = data.copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def import_data_sent(path, columns):\n",
    "    df = import_data(path)\n",
    "    sentimental_data = df[columns]\n",
    "    sent_df = sentimental_data.copy()\n",
    "\n",
    "    return sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ee423-24f9-427a-98f4-afe16556e6fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. Basic Formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac21e04-02ba-4348-aae2-7c5c3b71cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_formating(df, columns):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float64,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - columns (list): define which columns of df refere to which variable\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: formated DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    formated_df = df.rename(columns={\n",
    "        columns[0]: 'date',\n",
    "        columns[1]: 'open',\n",
    "        columns[2]: 'high',\n",
    "        columns[3]: 'low',\n",
    "        columns[4]: 'adj_close',\n",
    "        columns[5]: 'volume'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    formated_df = formated_df.astype({'open': 'float32', 'high': 'float32', 'low': 'float32', 'adj_close': 'float32', 'volume': 'float32'})\n",
    "\n",
    "    # Step 3: Drop all other columns\n",
    "    columns_to_keep = ['date', 'open', 'high', 'low', 'adj_close', 'volume']\n",
    "    formated_df = formated_df[columns_to_keep]\n",
    "\n",
    "    # Step 4: Set 'date' column to datetime type\n",
    "    formated_df['date'] = pd.to_datetime(formated_df['date'], format='mixed')\n",
    "\n",
    "    # Step 5: Set 'date' column as the index\n",
    "    formated_df.set_index('date', inplace=True)\n",
    "\n",
    "    return formated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89162f6-0524-468a-a469-647985f7175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_df_formating(sent_df, columns_sent):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float32,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - sent_df (pd.DataFrame): Input DataFrame.\n",
    "    - columns_sent (list): define which columns of df refere to which price data\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: formated DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    sent_df = sent_df.rename(columns={\n",
    "        columns_sent[0]: 'date',\n",
    "        columns_sent[1]: 'score',\n",
    "        columns_sent[2]: 'total',\n",
    "        columns_sent[3]: 'positive',\n",
    "        columns_sent[4]: 'negative'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    sent_df = sent_df.astype({'score': 'float32', 'total': 'float32', 'positive': 'float32', 'negative': 'float32'})\n",
    "\n",
    "    # Step 3: Set 'date' column to datetime type\n",
    "    sent_df['date'] = pd.to_datetime(sent_df['date'], format='mixed')\n",
    "\n",
    "    # Step 4: Set 'date' column as the index\n",
    "    sent_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Step 4: Drop Nan rows\n",
    "    sent_formated_df = sent_df.dropna()\n",
    "    \n",
    "    return sent_formated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bafade04-eff3-47b7-992a-8c1947e259a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_df_formating(df, columns_price):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float32,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - columns_price (list): define which columns of df refere to which variable\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: formated DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    formated_df = df.rename(columns={\n",
    "        columns_price[0]: 'date',\n",
    "        columns_price[1]: 'open',\n",
    "        columns_price[2]: 'adj_close'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    formated_df = formated_df.astype({'open': 'float32', 'adj_close': 'float32'})\n",
    "\n",
    "    # Step 3: Drop all other columns\n",
    "    columns_to_keep = ['date', 'open', 'adj_close']\n",
    "    formated_df = formated_df[columns_to_keep]\n",
    "\n",
    "    # Step 4: Set 'date' column to datetime type\n",
    "    formated_df['date'] = pd.to_datetime(formated_df['date'], format='mixed')\n",
    "\n",
    "    # Step 5: Set 'date' column as the index\n",
    "    formated_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Step 6: Drop Nan rows\n",
    "    price_formated_df = formated_df.dropna()\n",
    "\n",
    "    return price_formated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d1a7e0-f04a-4534-9ca7-10ba1eb6d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_df(formated_df):\n",
    "    \"\"\"\n",
    "    Label a DataFrame by creating a new column 'label', set all values to 0 in that column, \n",
    "    set the values to 1 if open price is lower than adjusted close.\n",
    "\n",
    "    Parameters:\n",
    "    - formated_df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: labeled DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a new column 'Label' and initialize with 0 (down)\n",
    "    formated_df['label'] = 0\n",
    "\n",
    "    # Step 2: Label +1 (up) where 'Open' is lower than 'Adj Close'\n",
    "    formated_df.loc[formated_df['open'] < formated_df['adj_close'], 'label'] = 1\n",
    "\n",
    "    # Step 4: Rename df\n",
    "    labeled_df = formated_df\n",
    "\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7647a47d-8a53-4702-910b-bec1200d3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(labeled_df, sent_formated_df):\n",
    "    \"\"\"\n",
    "    Merge two DataFrame with the inner merge method to keep a df of values for the matching indexes.\n",
    "\n",
    "    Parameters:\n",
    "    - labeled_df (pd.DataFrame): Input DataFrame.\n",
    "    - sent_formated_df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: merged DataFrame.\n",
    "    \"\"\"\n",
    "    # Merge two df on their indexes\n",
    "    merged_df = pd.merge(labeled_df, sent_formated_df, left_index=True, right_index=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6964b43-20ac-4fae-8685-817016381309",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74503bf3-0d0e-41af-89f3-04cb69fdd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_basic_formating(path, columns_price):\n",
    "    df = import_data(path)\n",
    "    \n",
    "    price_formated_df = price_df_formating(df, columns_price)\n",
    "    price_labeled_df = labeling_df(price_formated_df)\n",
    "\n",
    "    return price_labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda86a24-4fc8-43a2-b9ea-10f0856d456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_basic_formating(path, columns):\n",
    "    df = import_data(path)\n",
    "    \n",
    "    formated_df = df_formating(df, columns)\n",
    "    labeled_df = labeling_df(formated_df)\n",
    "\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba732d5-14cc-4018-804c-af2225334967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_and_features_basic_formating(path, columns_sent, columns):\n",
    "    df = import_data(path)\n",
    "    sent_df = import_data_sent(path, columns_sent)\n",
    "\n",
    "    formated_df = df_formating(df, columns)\n",
    "    labeled_df = labeling_df(formated_df)\n",
    "    sent_formated_df = sent_df_formating(sent_df, columns_sent)\n",
    "    merged_df = merge_df(labeled_df, sent_formated_df)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776cf68-9808-4b4a-a534-4f61a071d141",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329c167-9809-4772-926e-8a27426e497c",
   "metadata": {},
   "source": [
    "### A. Moving Average (MA(5) & MA(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9b324e-befc-495d-9053-172b782005c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_averages(df, column_name='adj_close', window_sizes=[5, 20]):\n",
    "    \"\"\"\n",
    "    Add Moving Averages (MA) columns to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which moving averages are calculated.\n",
    "    - window_sizes (list): List of window sizes for moving averages. Default is [5, 20].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added MA columns.\n",
    "    \"\"\"\n",
    "    for window_size in window_sizes:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603044c-819f-4be7-8a8f-558da114da44",
   "metadata": {},
   "source": [
    "### B. Bollinger Band (BB up & BB down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbabf05-d41d-471f-b62d-84bab447f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_bands(df, column_name='adj_close', window_size=20, num_std_dev=2):\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Bollinger Bands are calculated.\n",
    "    - window_size (int): Window size for the moving average. Default is 20.\n",
    "    - num_std_dev (int): Number of standard deviations for the upper and lower bands. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Bollinger Bands (BB up, BB down).\n",
    "    \"\"\"\n",
    "    # Calculate the rolling mean (middle band)\n",
    "    df['middle_band'] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    # Calculate the rolling standard deviation\n",
    "    df['std_dev'] = df[column_name].rolling(window=window_size).std()\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    df['bb_up'] = df['middle_band'] + num_std_dev * df['std_dev']\n",
    "    df['bb_down'] = df['middle_band'] - num_std_dev * df['std_dev']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['middle_band', 'std_dev'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3e935-62cb-4412-8edf-01dd55ed47c3",
   "metadata": {},
   "source": [
    "### C. Relative Difference in the Percentage of the price (RDP(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d77891ea-ba0c-45ab-84e7-e578b9f8e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdp(df, column_name='adj_close'):\n",
    "    \"\"\"\n",
    "    Calculate Relative Difference in the Percentage of the price (RDP(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RDP(1) is calculated.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RDP(1).\n",
    "    \"\"\"\n",
    "    # Calculate RDP(1)\n",
    "    df['rdp_1'] = df[column_name].pct_change() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534da867-c707-4617-b4e1-149ad39e8429",
   "metadata": {},
   "source": [
    "### D. Bias Ratio (BIAS(6), BIAS(12) & BIAS(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f187853b-4176-4eed-93c1-98b342c226d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(df, column_name='adj_close', ma_windows=[6, 12, 24]):\n",
    "    \"\"\"\n",
    "    Calculate Bias Ratios (BIAS) for specified moving average windows for a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which BIAS is calculated.\n",
    "    - ma_windows (list): List of moving average window sizes. Default is [6, 12, 24].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for BIAS(6), BIAS(12), and BIAS(24).\n",
    "    \"\"\"\n",
    "    for window_size in ma_windows:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        bias_column_name = f'BIAS_{window_size}'\n",
    "\n",
    "        # Calculate the moving average\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "        # Calculate BIAS\n",
    "        df[bias_column_name] = ((df[column_name] - df[ma_column_name]) / df[ma_column_name]) * 100\n",
    "\n",
    "        # Drop intermediate columns\n",
    "        df.drop(ma_column_name, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463acc7-c88c-4f55-b214-e7035395d938",
   "metadata": {},
   "source": [
    "### E. Relative Strength Index (RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e26827fd-fa8a-4b4f-9cd6-ebfb8e8266ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(df, column_name='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate the Relative Strength Index (RSI) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RSI is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for RSI calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RSI.\n",
    "    \"\"\"\n",
    "    # Calculate daily price changes\n",
    "    df['price_change'] = df[column_name].diff()\n",
    "\n",
    "    # Calculate the average gain and average loss over the specified window\n",
    "    df['gain'] = df['price_change'].apply(lambda x: x if x > 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "    df['loss'] = -df['price_change'].apply(lambda x: x if x < 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate relative strength (RS)\n",
    "    df['rs'] = df['gain'] / df['loss']\n",
    "\n",
    "    # Calculate RSI\n",
    "    df['rsi'] = 100 - (100 / (1 + df['rs']))\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_change', 'gain', 'loss', 'rs'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5d5be-103e-479d-b0fa-702fcd15fce1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### F. Exponential Moving Average (EMA(12) & EMA(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4594634-272d-4b7e-a260-2a0de467a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(df, column_name='adj_close', ema_short=12, ema_long=26):\n",
    "    \"\"\"\n",
    "    Calculate Exponential Moving Averages (EMA) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which EMA is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for EMA(12) and EMA(26).\n",
    "    \"\"\"\n",
    "    # Calculate EMA(12)\n",
    "    df['ema_12'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate EMA(26)\n",
    "    df['ema_26'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfeb2e-3f58-43da-b170-293c411467a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### G. Moving Average Convergence/Divergence (MACD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0619166-d66f-4709-bfef-d9d0f103a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(df, column_name='adj_close', ema_short=12, ema_long=26, signal_period=9):\n",
    "    \"\"\"\n",
    "    Calculate Moving Average Convergence Divergence (MACD) and its signal line for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which MACD is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "    - signal_period (int): Signal line EMA window size. Default is 9.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for MACD, Signal Line, and MACD Histogram.\n",
    "    \"\"\"\n",
    "    # Calculate short-term EMA\n",
    "    df['ema_short'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate long-term EMA\n",
    "    df['ema_long'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Line\n",
    "    df['dif'] = df['ema_short'] - df['ema_long']\n",
    "\n",
    "    # Calculate Signal Line\n",
    "    df['signal_line'] = df['dif'].ewm(span=signal_period, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Histogram\n",
    "    df['osc'] = df['dif'] - df['signal_line']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ema_short', 'ema_long'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c3ac-ca21-4a66-b338-35332a7c50fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### H. Psychological Line (PSY(12) & PSY(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "101c496e-8763-4f17-8f33-272e353c845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psy(df, column_name='adj_close', psy_short=12, psy_long=24):\n",
    "    \"\"\"\n",
    "    Calculate Psychological Line (PSY) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PSY is calculated. Default is 'Close'.\n",
    "    - psy_short (int): Short-term PSY window size. Default is 12.\n",
    "    - psy_long (int): Long-term PSY window size. Default is 24.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for PSY(12) and PSY(24).\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of days where the closing price is higher than the previous day's closing price\n",
    "    df['price_up'] = df[column_name].diff() > 0\n",
    "\n",
    "    # Calculate PSY(12)\n",
    "    df['psy_12'] = df['price_up'].rolling(window=psy_short).mean() * 100\n",
    "\n",
    "    # Calculate PSY(24)\n",
    "    df['psy_24'] = df['price_up'].rolling(window=psy_long).mean() * 100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_up'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd2fc5-4c0c-43d1-bec3-fa6185e1ab74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### I. Williams %R (WMS%R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54569384-663b-47b4-ac6e-822fee40d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def williams_percent_r(df, high_column='high', low_column='low', adj_close_column='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate Williams %R for a specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - adj_close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - window (int): Window size for Williams %R calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Williams %R.\n",
    "    \"\"\"\n",
    "    # Calculate highest high and lowest low over the specified window\n",
    "    df['hh'] = df[high_column].rolling(window=window).max()\n",
    "    df['ll'] = df[low_column].rolling(window=window).min()\n",
    "\n",
    "    # Calculate Williams %R\n",
    "    df['williams_%r'] = (df['hh'] - df[adj_close_column]) / (df['hh'] - df['ll']) * -100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['hh', 'll'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320471bc-2ca7-441c-8f1c-63cb753e42f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### J. Stochastic Oscillator (Stochastic%K & Stochastic%D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deef3936-e6e2-4ca0-862f-47b1fa153512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_oscillator(df, high_column='high', low_column='low', adj_close_column='adj_close', k_window=14, d_window=3):\n",
    "    \"\"\"\n",
    "    Calculate Stochastic Oscillator (%K and %D) for specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - k_window (int): Window size for %K calculation. Default is 14.\n",
    "    - d_window (int): Window size for %D calculation. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Stochastic %K and %D.\n",
    "    \"\"\"\n",
    "    # Calculate lowest low and highest high over the specified window\n",
    "    df['ll'] = df[low_column].rolling(window=k_window).min()\n",
    "    df['hh'] = df[high_column].rolling(window=k_window).max()\n",
    "\n",
    "    # Calculate Stochastic %K\n",
    "    df['stochastic_%k'] = ((df[adj_close_column] - df['ll']) / (df['hh'] - df['ll'])) * 100\n",
    "\n",
    "    # Calculate Stochastic %D (3-day simple moving average of %K)\n",
    "    df['stochastic_%d'] = df['stochastic_%k'].rolling(window=d_window).mean()\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ll', 'hh'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b34ad4-a675-4431-8e0a-48de2eb22dc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### K. Percentage of Price Change (PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b244a954-0e2b-46b6-a5ae-4ddbda1dd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Percentage of Price Change (PROC) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PROC is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for PROC calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for PROC.\n",
    "    \"\"\"\n",
    "    # Calculate the percentage change in price using rolling window\n",
    "    df['proc'] = df[column_name].pct_change().rolling(window=window).mean() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee3aac-2183-4402-9547-ebbd1602bebd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### L. Momentum (MO(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b681bfb-ee2c-4c43-aef3-e121a603be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Momentum (MO) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Momentum is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for Momentum calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Momentum.\n",
    "    \"\"\"\n",
    "    # Calculate the difference in price over the specified window\n",
    "    df['momentum'] = df[column_name].diff(window)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1327d00-c61d-4fa7-b144-fa077790c250",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### M. First-Order Lag (LAG(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf2336b9-6545-4d62-87cc-441b58683cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_lag(df, column_name='adj_close', lag=1):\n",
    "    \"\"\"\n",
    "    Calculate First-Order Lag (LAG(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which the lag is calculated. Default is 'Close'.\n",
    "    - lag (int): Number of periods to lag. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for the First-Order Lag.\n",
    "    \"\"\"\n",
    "    # Calculate the First-Order Lag using the shift() method\n",
    "    df[f'LAG_{lag}'] = df[column_name].shift(lag)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3dc06-f6e6-4022-9cef-a19c8516bd4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### N. Trading Volume (VOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b1cb210-531e-4b23-89b5-8d1750598016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_volume(df, volume_column='volume'):\n",
    "    \"\"\"\n",
    "    Calculate Trading Volume (VOL) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - volume_column (str): Name of the column containing trading volume. Default is 'Volume'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Trading Volume.\n",
    "    \"\"\"\n",
    "    df['vol'] = df[volume_column]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2944b5-c0e6-40f3-aea0-02878e7708f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### O. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c7db5bc-6d95-48b3-8222-7fbce1dc940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    moving_averages(df)\n",
    "    bollinger_bands(df)\n",
    "    rdp(df)\n",
    "    bias(df)\n",
    "    rsi(df)\n",
    "    ema(df)\n",
    "    macd(df)\n",
    "    psy(df)\n",
    "    williams_percent_r(df)\n",
    "    stochastic_oscillator(df)\n",
    "    proc(df)\n",
    "    momentum(df)\n",
    "    first_order_lag(df)\n",
    "    trading_volume(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb30e62-be2d-4850-824d-b81707b82606",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8577e4-d93e-4919-9c59-29f7fe9c1f50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. Removing columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0720001a-a6bc-4020-b581-96dfb5a124dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, columns_to_drop=['open', 'high', 'low', 'adj_close', 'volume']):\n",
    "    \"\"\"\n",
    "    Drop specified columns from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - columns_to_drop (list): List of column names to drop. Default is ['Open', 'High', 'Low', 'Adj_Close', 'Volume'].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with specified columns dropped.\n",
    "    \"\"\"\n",
    "    # Drop specified columns\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13cbf4b6-e107-4baa-b31f-df5b0cfa1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(df):\n",
    "    \"\"\"\n",
    "    Drop all rows with NaN values from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with NaN rows dropped.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN values\n",
    "    cleaned_df = df.dropna()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83214a7-776d-4175-a7fb-7d51d2803da1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e83d8fbd-faf8-4f74-80c3-7332bb6a4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataframe(df):\n",
    "    \"\"\"\n",
    "    Scale a DataFrame using Standard scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Scaled DataFrame.\n",
    "    \"\"\"\n",
    "    # Scale the selected columns\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    index_column = df.index\n",
    "    \n",
    "    label_column = df['label']\n",
    "    int_df = df.drop(columns=['label'])\n",
    "    \n",
    "    columns_to_scale = int_df.columns\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(int_df), columns=columns_to_scale)\n",
    "    scaled_df.index = index_column\n",
    "    scaled_df['label'] = label_column\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fec9b-e75c-4506-ba16-889cb9530c06",
   "metadata": {},
   "source": [
    "### d. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "003458b2-8156-43d8-972f-d653db94c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split a time series dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df: the input time series dataset.\n",
    "    - test_size (float): the proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "    - df_train, df_test: Pandas arrays, representing features and target values for each set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract index number of splitting points\n",
    "    len_df = len(df)\n",
    "    index_1 = round(len_df*(1-(test_size)))\n",
    "    index_2 = index_1 +1\n",
    "\n",
    "    # Extract values at previously calculated splitting points\n",
    "    date_1 = df.index[index_1]\n",
    "    date_2 = df.index[index_2]\n",
    "\n",
    "    # Construct train_df, val_df and test_df\n",
    "    df_train = df[:date_1]\n",
    "    df_test = df[date_2:]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564e8e7-fb89-48f7-85aa-57c8d9a66aaa",
   "metadata": {},
   "source": [
    "### e. Reshape Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9524537-09e0-4957-b2c1-7e978255f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_matrix_split_X_y(df, window_size=5):\n",
    "    \"\"\"\n",
    "    Reshape a DataFrames into two 3D NumPy arrays \n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with a list of time series data\n",
    "    - window_size: the number of time steps to consider for each observation\n",
    "\n",
    "    Returns:\n",
    "    - X: (num_observations, window_size, num_features)\n",
    "    - y: (num_observations, num_features_to_predict)\n",
    "    \"\"\"\n",
    "    df_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    df_X = df.drop('label', axis=1)\n",
    "    df_y = df['label']\n",
    "\n",
    "    for i in range(len(df_np)-(window_size)):\n",
    "        row = df_X[i:i+window_size]\n",
    "        X.append(row)\n",
    "        label = df_y[i+(window_size)]\n",
    "        y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = np.expand_dims(y, axis=-1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe56d1-867b-4392-b157-412e6ea3f7b9",
   "metadata": {},
   "source": [
    "### f. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0325e9cb-776a-4ccf-9d68-e51a8ceadae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fadf6b0-2bed-4328-a86a-5feec7f3bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \n",
    "    clean_merged_df = drop_columns(df)\n",
    "    clean_merged_df = drop_rows(clean_merged_df)\n",
    "    scaled_clean_merged_df = scale_dataframe(clean_merged_df)\n",
    "    split_scaled_clean_merged_df = train_test_split(scaled_clean_merged_df)\n",
    "    X_train, y_train = input_matrix_split_X_y(split_scaled_clean_merged_df[0])\n",
    "    X_test, y_test = input_matrix_split_X_y(split_scaled_clean_merged_df[1])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7462ac85-0fec-4f71-8ff1-fa7be58ab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_price(df, columns_to_drop):\n",
    "    \n",
    "    clean_merged_df = drop_columns(df, columns_to_drop)\n",
    "    clean_merged_df = drop_rows(clean_merged_df)\n",
    "    scaled_clean_merged_df = scale_dataframe(clean_merged_df)\n",
    "    split_scaled_clean_merged_df = train_test_split(scaled_clean_merged_df)\n",
    "    X_train, y_train = input_matrix_split_X_y(split_scaled_clean_merged_df[0])\n",
    "    X_test, y_test = input_matrix_split_X_y(split_scaled_clean_merged_df[1])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaee1c3-079e-4bb2-ab98-66afeba90339",
   "metadata": {},
   "source": [
    "## 3. Models Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784a791-d646-4375-8eab-c3a9bdec0f30",
   "metadata": {},
   "source": [
    "### Prework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffafbfdc-5265-457c-b763-a737ca6dd22f",
   "metadata": {},
   "source": [
    "#### Val & Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72941804-24b1-4f10-b5e2-c56bc7367f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(model, X_test, y_test, verbose=0):\n",
    "\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=verbose)\n",
    "\n",
    "    return model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35a1966e-70c2-4680-8e75-c02b620128de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, X_test, threshold = 0.5):\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    binary_predictions = (y_pred >= threshold).astype(int)\n",
    "    binary_predictions = np.squeeze(binary_predictions)\n",
    "\n",
    "    return binary_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec0325-d2ab-4258-892e-7fec6ea6ffba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cd51c-f74c-4aac-861c-262b5a3fedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS --- \n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].legend(['Train', 'Val'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Val'], loc='best')\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4382c-d66a-4cf2-9344-26bdf7792877",
   "metadata": {},
   "source": [
    "### a. LSTM Model (all price features, 5D, 60min, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c23c3147-8f59-49e4-abfd-3d81a79630b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_19547/3659344757.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n",
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_19547/3659344757.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n"
     ]
    }
   ],
   "source": [
    "path = \"../../raw_data/pro_btc_60min_price_df_v2.csv\"\n",
    "columns = ['date', 'open', 'high', 'low', 'adj_close', 'volume']\n",
    "\n",
    "labeled_df = features_basic_formating(path, columns)\n",
    "feature_labeled_df = feature_engineering(labeled_df)\n",
    "f_X_train, f_y_train, f_X_test, f_y_test = preprocessing(feature_labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d7e18a6-406d-4c0c-bd1b-7439aeb64a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_initialization(X_train, window_size=5, loss_function='binary_crossentropy', metrics_list=['accuracy']):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.LSTM(units=10, activation='tanh', return_sequences=True, input_shape=(window_size, X_train.shape[-1]), kernel_regularizer=l2(0.5)))\n",
    "    model.add(layers.LSTM(units=3, activation='tanh', return_sequences=False))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = Adam(learning_rate=0.0001), \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fa7677f-87e8-40f3-963e-82b303fe8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_training(model, X_train, y_train, patience=50, validation_split=0.2, batch_size=64, epochs=100, verbose=0):\n",
    "\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es, reduce_lr],\n",
    "                        verbose=verbose)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df8f3f9e-5e28-4cbc-9506-9ca1cfddc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 0s 585us/step\n"
     ]
    }
   ],
   "source": [
    "f_lstm_model = lstm_model_initialization(f_X_train)\n",
    "f_lstm_history = lstm_model_training(f_lstm_model, f_X_train, f_y_train)\n",
    "f_lstm_model_acc = model_validation(f_lstm_model, f_X_test, f_y_test)\n",
    "f_lstm_y_pred = model_prediction(f_lstm_model, f_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f8e9a1b-7705-41b2-93de-6ce064a20337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6935366988182068, 0.497609943151474]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_lstm_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8822b323-841b-46cc-a363-d36e4dc92999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, None, 23)          47        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 10)          1360      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 3)                 168       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1652 (6.46 KB)\n",
      "Trainable params: 1605 (6.27 KB)\n",
      "Non-trainable params: 47 (192.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4987b18-5d5e-475f-b707-362aaa539c04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_loss_accuracy\u001b[49m(f_lstm_history)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe accuracy on the test set is of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_lstm_model_acc[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_loss_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss_accuracy(f_lstm_history)\n",
    "print(f'The accuracy on the test set is of {f_lstm_model_acc[1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53027725-e2d3-42d6-98c0-617df3e67f3c",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0fcc5-99de-428e-9ceb-ab44746e44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve1(y_true_cls, y_pred_prob):\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true_cls, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede36b2c-4ed9-4755-81f8-6b0917e4a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    squeezed_array = np.squeeze(y_true)\n",
    "    \n",
    "    if not title:\n",
    "        title = 'Confusion Matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(squeezed_array, y_pred)\n",
    "    \n",
    "    # Get class labels\n",
    "    classes = unique_labels(squeezed_array, y_pred)\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65823e2-b202-4b04-856b-101992c30a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(f_y_test, f_lstm_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5318d9-6354-400e-9378-75bb4f76fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve1(f_y_test, f_lstm_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
