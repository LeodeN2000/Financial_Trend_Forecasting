{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b315f3c-ae60-475d-8233-edcbeeaa69ee",
   "metadata": {},
   "source": [
    "# Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2278adb-9214-417e-a02e-54cdd24a208e",
   "metadata": {},
   "source": [
    "## 0. Imports & Basic formating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f650ae-24bc-4b2b-9f2c-b97a98812a5c",
   "metadata": {},
   "source": [
    "### a. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3af210-5758-4885-ba83-c77aad92cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "779cb5d3-0fff-43df-9397-ce92a041493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    #############################\n",
    "    #  1 - Import data          #\n",
    "    #############################\n",
    "    data = pd.read_csv(path)\n",
    "    df = data.copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "def import_data_sent(path, columns):\n",
    "    #############################\n",
    "    #  1 - Make copy of df      #\n",
    "    #############################\n",
    "    df = import_data(path)\n",
    "    sentimental_data = df[columns]\n",
    "    sent_df = sentimental_data.copy()\n",
    "\n",
    "    return sent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ee423-24f9-427a-98f4-afe16556e6fa",
   "metadata": {},
   "source": [
    "### b. Basic Formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac21e04-02ba-4348-aae2-7c5c3b71cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_formating(formated_df, formated_df_columns):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float64,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - define which columns of df refere to which price data\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    formated_df = formated_df.rename(columns={\n",
    "        formated_df_columns[0]: 'date',\n",
    "        formated_df_columns[1]: 'open',\n",
    "        formated_df_columns[2]: 'high',\n",
    "        formated_df_columns[3]: 'low',\n",
    "        formated_df_columns[4]: 'adj_close',\n",
    "        formated_df_columns[5]: 'volume'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    formated_df = formated_df.astype({'open': 'float32', 'high': 'float32', 'low': 'float32', 'adj_close': 'float32', 'volume': 'float32'})\n",
    "\n",
    "    # Step 3: Drop all other columns\n",
    "    columns_to_keep = ['date', 'open', 'high', 'low', 'adj_close', 'volume']\n",
    "    formated_df = formated_df[columns_to_keep]\n",
    "\n",
    "    # Step 4: Set 'date' column to datetime type\n",
    "    formated_df['date'] = pd.to_datetime(formated_df['date'], format='mixed')\n",
    "\n",
    "    # Step 5: Set 'date' column as the index\n",
    "    formated_df.set_index('date', inplace=True)\n",
    "\n",
    "    return formated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89162f6-0524-468a-a469-647985f7175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_df_formating(sent_df, sent_df_columns):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float64,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - define which columns of df refere to which price data\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    sent_df = sent_df.rename(columns={\n",
    "        sent_df_columns[0]: 'date',\n",
    "        sent_df_columns[1]: 'score',\n",
    "        sent_df_columns[2]: 'total',\n",
    "        sent_df_columns[3]: 'positive',\n",
    "        sent_df_columns[4]: 'negative'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    sent_df = sent_df.astype({'score': 'float32', 'total': 'float32', 'positive': 'float32', 'negative': 'float32'})\n",
    "\n",
    "    # Step 3: Set 'date' column to datetime type\n",
    "    sent_df['date'] = pd.to_datetime(sent_df['date'], format='mixed')\n",
    "\n",
    "    # Step 4: Set 'date' column as the index\n",
    "    sent_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Step 4: Drop Nan rows\n",
    "    sent_df = sent_df.dropna()\n",
    "    \n",
    "    return sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bafade04-eff3-47b7-992a-8c1947e259a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_df_formating(formated_df, formated_df_columns):\n",
    "    \"\"\"\n",
    "    Preprocess a DataFrame by renaming columns, setting columns to float64,\n",
    "    dropping unnecessary columns, setting the 'date' column to datetime type,\n",
    "    and setting the 'date' column as the index.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - define which columns of df refere to which price data\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename columns\n",
    "    formated_df = formated_df.rename(columns={\n",
    "        formated_df_columns[0]: 'date',\n",
    "        formated_df_columns[1]: 'open',\n",
    "        formated_df_columns[2]: 'adj_close'\n",
    "    })\n",
    "\n",
    "    # Step 2: Set columns to float64\n",
    "    formated_df = formated_df.astype({'open': 'float32', 'adj_close': 'float32'})\n",
    "\n",
    "    # Step 3: Drop all other columns\n",
    "    columns_to_keep = ['date', 'open', 'adj_close']\n",
    "    formated_df = formated_df[columns_to_keep]\n",
    "\n",
    "    # Step 4: Set 'date' column to datetime type\n",
    "    formated_df['date'] = pd.to_datetime(formated_df['date'], format='mixed')\n",
    "\n",
    "    # Step 5: Set 'date' column as the index\n",
    "    formated_df.set_index('date', inplace=True)\n",
    "\n",
    "    # Step 6: Drop Nan rows\n",
    "    price_formated_df = formated_df.dropna()\n",
    "\n",
    "    return price_formated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d1a7e0-f04a-4534-9ca7-10ba1eb6d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_df(labeled_df):\n",
    "    # Create a new column 'Label' and initialize with 0 (constant)\n",
    "    labeled_df['label'] = 0\n",
    "    \n",
    "    # Label -1 (down) where 'Open' is higher than 'Adj Close'\n",
    "    labeled_df.loc[labeled_df['open'] > labeled_df['adj_close'], 'label'] = 0\n",
    "\n",
    "    # Label +1 (up) where 'Open' is lower than 'Adj Close'\n",
    "    labeled_df.loc[labeled_df['open'] < labeled_df['adj_close'], 'label'] = 1\n",
    "\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7647a47d-8a53-4702-910b-bec1200d3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df, sent_df):\n",
    "    \n",
    "    # Merge two df on their indexes\n",
    "    merged_df = pd.merge(df, sent_df, left_index=True, right_index=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776cf68-9808-4b4a-a534-4f61a071d141",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329c167-9809-4772-926e-8a27426e497c",
   "metadata": {},
   "source": [
    "### A. Moving Average (MA(5) & MA(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9b324e-befc-495d-9053-172b782005c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_averages(df, column_name='adj_close', window_sizes=[5, 20]):\n",
    "    \"\"\"\n",
    "    Add Moving Averages (MA) columns to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which moving averages are calculated.\n",
    "    - window_sizes (list): List of window sizes for moving averages. Default is [5, 20].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added MA columns.\n",
    "    \"\"\"\n",
    "    for window_size in window_sizes:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603044c-819f-4be7-8a8f-558da114da44",
   "metadata": {},
   "source": [
    "### B. Bollinger Band (BB up & BB down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbabf05-d41d-471f-b62d-84bab447f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_bands(df, column_name='adj_close', window_size=20, num_std_dev=2):\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Bollinger Bands are calculated.\n",
    "    - window_size (int): Window size for the moving average. Default is 20.\n",
    "    - num_std_dev (int): Number of standard deviations for the upper and lower bands. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Bollinger Bands (BB up, BB down).\n",
    "    \"\"\"\n",
    "    # Calculate the rolling mean (middle band)\n",
    "    df['middle_band'] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    # Calculate the rolling standard deviation\n",
    "    df['std_dev'] = df[column_name].rolling(window=window_size).std()\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    df['bb_up'] = df['middle_band'] + num_std_dev * df['std_dev']\n",
    "    df['bb_down'] = df['middle_band'] - num_std_dev * df['std_dev']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['middle_band', 'std_dev'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3e935-62cb-4412-8edf-01dd55ed47c3",
   "metadata": {},
   "source": [
    "### C. Relative Difference in the Percentage of the price (RDP(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d77891ea-ba0c-45ab-84e7-e578b9f8e1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdp(df, column_name='adj_close'):\n",
    "    \"\"\"\n",
    "    Calculate Relative Difference in the Percentage of the price (RDP(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RDP(1) is calculated.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RDP(1).\n",
    "    \"\"\"\n",
    "    # Calculate RDP(1)\n",
    "    df['rdp_1'] = df[column_name].pct_change() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534da867-c707-4617-b4e1-149ad39e8429",
   "metadata": {},
   "source": [
    "### D. Bias Ratio (BIAS(6), BIAS(12) & BIAS(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f187853b-4176-4eed-93c1-98b342c226d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(df, column_name='adj_close', ma_windows=[6, 12, 24]):\n",
    "    \"\"\"\n",
    "    Calculate Bias Ratios (BIAS) for specified moving average windows for a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which BIAS is calculated.\n",
    "    - ma_windows (list): List of moving average window sizes. Default is [6, 12, 24].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for BIAS(6), BIAS(12), and BIAS(24).\n",
    "    \"\"\"\n",
    "    for window_size in ma_windows:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        bias_column_name = f'BIAS_{window_size}'\n",
    "\n",
    "        # Calculate the moving average\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "        # Calculate BIAS\n",
    "        df[bias_column_name] = ((df[column_name] - df[ma_column_name]) / df[ma_column_name]) * 100\n",
    "\n",
    "        # Drop intermediate columns\n",
    "        df.drop(ma_column_name, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463acc7-c88c-4f55-b214-e7035395d938",
   "metadata": {},
   "source": [
    "### E. Relative Strength Index (RSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26827fd-fa8a-4b4f-9cd6-ebfb8e8266ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(df, column_name='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate the Relative Strength Index (RSI) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RSI is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for RSI calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RSI.\n",
    "    \"\"\"\n",
    "    # Calculate daily price changes\n",
    "    df['price_change'] = df[column_name].diff()\n",
    "\n",
    "    # Calculate the average gain and average loss over the specified window\n",
    "    df['gain'] = df['price_change'].apply(lambda x: x if x > 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "    df['loss'] = -df['price_change'].apply(lambda x: x if x < 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate relative strength (RS)\n",
    "    df['rs'] = df['gain'] / df['loss']\n",
    "\n",
    "    # Calculate RSI\n",
    "    df['rsi'] = 100 - (100 / (1 + df['rs']))\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_change', 'gain', 'loss', 'rs'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5d5be-103e-479d-b0fa-702fcd15fce1",
   "metadata": {},
   "source": [
    "### F. Exponential Moving Average (EMA(12) & EMA(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4594634-272d-4b7e-a260-2a0de467a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(df, column_name='adj_close', ema_short=12, ema_long=26):\n",
    "    \"\"\"\n",
    "    Calculate Exponential Moving Averages (EMA) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which EMA is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for EMA(12) and EMA(26).\n",
    "    \"\"\"\n",
    "    # Calculate EMA(12)\n",
    "    df['ema_12'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate EMA(26)\n",
    "    df['ema_26'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dfeb2e-3f58-43da-b170-293c411467a7",
   "metadata": {},
   "source": [
    "### G. Moving Average Convergence/Divergence (MACD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0619166-d66f-4709-bfef-d9d0f103a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(df, column_name='adj_close', ema_short=12, ema_long=26, signal_period=9):\n",
    "    \"\"\"\n",
    "    Calculate Moving Average Convergence Divergence (MACD) and its signal line for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which MACD is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "    - signal_period (int): Signal line EMA window size. Default is 9.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for MACD, Signal Line, and MACD Histogram.\n",
    "    \"\"\"\n",
    "    # Calculate short-term EMA\n",
    "    df['ema_short'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate long-term EMA\n",
    "    df['ema_long'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Line\n",
    "    df['dif'] = df['ema_short'] - df['ema_long']\n",
    "\n",
    "    # Calculate Signal Line\n",
    "    df['signal_line'] = df['dif'].ewm(span=signal_period, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Histogram\n",
    "    df['osc'] = df['dif'] - df['signal_line']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ema_short', 'ema_long'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c3ac-ca21-4a66-b338-35332a7c50fa",
   "metadata": {},
   "source": [
    "### H. Psychological Line (PSY(12) & PSY(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101c496e-8763-4f17-8f33-272e353c845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psy(df, column_name='adj_close', psy_short=12, psy_long=24):\n",
    "    \"\"\"\n",
    "    Calculate Psychological Line (PSY) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PSY is calculated. Default is 'Close'.\n",
    "    - psy_short (int): Short-term PSY window size. Default is 12.\n",
    "    - psy_long (int): Long-term PSY window size. Default is 24.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for PSY(12) and PSY(24).\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of days where the closing price is higher than the previous day's closing price\n",
    "    df['price_up'] = df[column_name].diff() > 0\n",
    "\n",
    "    # Calculate PSY(12)\n",
    "    df['psy_12'] = df['price_up'].rolling(window=psy_short).mean() * 100\n",
    "\n",
    "    # Calculate PSY(24)\n",
    "    df['psy_24'] = df['price_up'].rolling(window=psy_long).mean() * 100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_up'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd2fc5-4c0c-43d1-bec3-fa6185e1ab74",
   "metadata": {},
   "source": [
    "### I. Williams %R (WMS%R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54569384-663b-47b4-ac6e-822fee40d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def williams_percent_r(df, high_column='high', low_column='low', adj_close_column='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate Williams %R for a specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - adj_close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - window (int): Window size for Williams %R calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Williams %R.\n",
    "    \"\"\"\n",
    "    # Calculate highest high and lowest low over the specified window\n",
    "    df['hh'] = df[high_column].rolling(window=window).max()\n",
    "    df['ll'] = df[low_column].rolling(window=window).min()\n",
    "\n",
    "    # Calculate Williams %R\n",
    "    df['williams_%r'] = (df['hh'] - df[adj_close_column]) / (df['hh'] - df['ll']) * -100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['hh', 'll'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320471bc-2ca7-441c-8f1c-63cb753e42f1",
   "metadata": {},
   "source": [
    "### J. Stochastic Oscillator (Stochastic%K & Stochastic%D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deef3936-e6e2-4ca0-862f-47b1fa153512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_oscillator(df, high_column='high', low_column='low', adj_close_column='adj_close', k_window=14, d_window=3):\n",
    "    \"\"\"\n",
    "    Calculate Stochastic Oscillator (%K and %D) for specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - k_window (int): Window size for %K calculation. Default is 14.\n",
    "    - d_window (int): Window size for %D calculation. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Stochastic %K and %D.\n",
    "    \"\"\"\n",
    "    # Calculate lowest low and highest high over the specified window\n",
    "    df['ll'] = df[low_column].rolling(window=k_window).min()\n",
    "    df['hh'] = df[high_column].rolling(window=k_window).max()\n",
    "\n",
    "    # Calculate Stochastic %K\n",
    "    df['stochastic_%k'] = ((df[adj_close_column] - df['ll']) / (df['hh'] - df['ll'])) * 100\n",
    "\n",
    "    # Calculate Stochastic %D (3-day simple moving average of %K)\n",
    "    df['stochastic_%d'] = df['stochastic_%k'].rolling(window=d_window).mean()\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ll', 'hh'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b34ad4-a675-4431-8e0a-48de2eb22dc1",
   "metadata": {},
   "source": [
    "### K. Percentage of Price Change (PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b244a954-0e2b-46b6-a5ae-4ddbda1dd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Percentage of Price Change (PROC) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PROC is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for PROC calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for PROC.\n",
    "    \"\"\"\n",
    "    # Calculate the percentage change in price using rolling window\n",
    "    df['proc'] = df[column_name].pct_change().rolling(window=window).mean() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee3aac-2183-4402-9547-ebbd1602bebd",
   "metadata": {},
   "source": [
    "### L. Momentum (MO(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b681bfb-ee2c-4c43-aef3-e121a603be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Momentum (MO) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Momentum is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for Momentum calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Momentum.\n",
    "    \"\"\"\n",
    "    # Calculate the difference in price over the specified window\n",
    "    df['momentum'] = df[column_name].diff(window)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1327d00-c61d-4fa7-b144-fa077790c250",
   "metadata": {},
   "source": [
    "### M. First-Order Lag (LAG(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf2336b9-6545-4d62-87cc-441b58683cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_lag(df, column_name='adj_close', lag=1):\n",
    "    \"\"\"\n",
    "    Calculate First-Order Lag (LAG(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which the lag is calculated. Default is 'Close'.\n",
    "    - lag (int): Number of periods to lag. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for the First-Order Lag.\n",
    "    \"\"\"\n",
    "    # Calculate the First-Order Lag using the shift() method\n",
    "    df[f'LAG_{lag}'] = df[column_name].shift(lag)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3dc06-f6e6-4022-9cef-a19c8516bd4a",
   "metadata": {},
   "source": [
    "### N. Trading Volume (VOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1cb210-531e-4b23-89b5-8d1750598016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_volume(df, volume_column='volume'):\n",
    "    \"\"\"\n",
    "    Calculate Trading Volume (VOL) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - volume_column (str): Name of the column containing trading volume. Default is 'Volume'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Trading Volume.\n",
    "    \"\"\"\n",
    "    df['vol'] = df[volume_column]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb30e62-be2d-4850-824d-b81707b82606",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8577e4-d93e-4919-9c59-29f7fe9c1f50",
   "metadata": {},
   "source": [
    "### a. Removing columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0720001a-a6bc-4020-b581-96dfb5a124dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, columns_to_drop=['open', 'high', 'low', 'adj_close', 'volume']):\n",
    "    \"\"\"\n",
    "    Drop specified columns from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - columns_to_drop (list): List of column names to drop. Default is ['Open', 'High', 'Low', 'Adj_Close', 'Volume'].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with specified columns dropped.\n",
    "    \"\"\"\n",
    "    # Drop specified columns\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13cbf4b6-e107-4baa-b31f-df5b0cfa1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows(df):\n",
    "    \"\"\"\n",
    "    Drop all rows with NaN values from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with NaN rows dropped.\n",
    "    - list: List of indices corresponding to dropped rows.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN values\n",
    "    cleaned_df = df.dropna()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83214a7-776d-4175-a7fb-7d51d2803da1",
   "metadata": {},
   "source": [
    "### b. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e83d8fbd-faf8-4f74-80c3-7332bb6a4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataframe(df):\n",
    "    \"\"\"\n",
    "    Scale a DataFrame using Standard scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Scaled DataFrame.\n",
    "    \"\"\"\n",
    "    # Scale the selected columns\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    index_column = df.index\n",
    "    \n",
    "    date_column = df['label']\n",
    "    int_df = df.drop(columns=['label'])\n",
    "    \n",
    "    columns_to_scale = int_df.columns\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(int_df), columns=columns_to_scale)\n",
    "    scaled_df.index = index_column\n",
    "    scaled_df['label'] = date_column\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461fec9b-e75c-4506-ba16-889cb9530c06",
   "metadata": {},
   "source": [
    "### c. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003458b2-8156-43d8-972f-d653db94c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split a time series dataset into training, testing, and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df: NumPy array or matrix, the input time series dataset.\n",
    "    - test_size: Float, the proportion of the dataset to include in the test split.\n",
    "    - val_size: Float, the proportion of the dataset to include in the validation split.\n",
    "\n",
    "    Returns:\n",
    "    - df_train, df_test: Pandas arrays, representing features and target values for each set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract index number of splitting points\n",
    "    len_df = len(df)\n",
    "    index_1 = round(len_df*(1-(test_size)))\n",
    "    index_2 = index_1 +1\n",
    "\n",
    "    # Extract values at previously calculated splitting points\n",
    "    date_1 = df.index[index_1]\n",
    "    date_2 = df.index[index_2]\n",
    "\n",
    "    # Construct train_df, val_df and test_df\n",
    "    df_train = df[:date_1]\n",
    "    df_test = df[date_2:]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564e8e7-fb89-48f7-85aa-57c8d9a66aaa",
   "metadata": {},
   "source": [
    "### d. Reshape Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9524537-09e0-4957-b2c1-7e978255f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_matrix_split_X_y(df, window_size=5):\n",
    "    \"\"\"\n",
    "    Reshape a DataFrame into a 3D NumPy arrays (num_observations, window_size, num_features)\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with a list of time series data\n",
    "    - sequence_length: the number of time steps to consider for each observation\n",
    "\n",
    "    Returns:\n",
    "    - X, y: a 3D NumPy arrays, one for the features and one for the lables\n",
    "    \"\"\"\n",
    "    df_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    df_X = df.drop('label', axis=1)\n",
    "    df_y = df['label']\n",
    "\n",
    "    for i in range(len(df_np)-(window_size)):\n",
    "        row = df_X[i:i+window_size]\n",
    "        X.append(row)\n",
    "        label = df_y[i+(window_size)]\n",
    "        y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y = np.expand_dims(y, axis=-1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaee1c3-079e-4bb2-ab98-66afeba90339",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Model Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4382c-d66a-4cf2-9344-26bdf7792877",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72941804-24b1-4f10-b5e2-c56bc7367f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(X_train, y_train, X_test, y_test, window_size=5, optimizer_name='adam', loss_function='binary_crossentropy', metrics_list=['accuracy'], patience=5, validation_split=0.2, batch_size=64, epochs=100, verbose=1):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    # [1, 5] layers\n",
    "    # nodes per layer [30, 70]\n",
    "    # activation function: relu\n",
    "    # optimizer: Adam\n",
    "    # learning rate = [0.001, 0.1]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = optimizer_name, \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    #############################\n",
    "    #  3 - Training Method  #\n",
    "    #############################\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    #############################\n",
    "    #  4 - Validation Method  #\n",
    "    #############################\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return model, history, model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81495939-8d80-42d9-b488-87f7784d054d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d91f901-9dc7-4c3e-9162-286949b00a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(X_train, y_train, X_test, y_test, window_size=5, optimizer_name='adam', loss_function='binary_crossentropy', metrics_list=['accuracy'], patience=5, validation_split=0.2, batch_size=64, epochs=100, verbose=1):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    # [1, 5] layers\n",
    "    # nodes per layer [30, 70]\n",
    "    # activation function: relu\n",
    "    # optimizer: Adam\n",
    "    # learning rate = [0.001, 0.1]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = optimizer_name, \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    #############################\n",
    "    #  3 - Training Method  #\n",
    "    #############################\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    #############################\n",
    "    #  4 - Validation Method  #\n",
    "    #############################\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return model, history, model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7687d01-ae84-46f2-a178-6c13a3a9f605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "166a2234-2f75-4d4e-a440-ca84e175cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_model(X_train, y_train, X_test, y_test, window_size=5, optimizer_name='adam', loss_function='binary_crossentropy', metrics_list=['accuracy'], patience=5, validation_split=0.2, batch_size=64, epochs=100, verbose=1):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    # [1, 5] layers\n",
    "    # nodes per layer [30, 70]\n",
    "    # activation function: relu\n",
    "    # optimizer: Adam\n",
    "    # learning rate = [0.001, 0.1]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = optimizer_name, \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    #############################\n",
    "    #  3 - Training Method  #\n",
    "    #############################\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    #############################\n",
    "    #  4 - Validation Method  #\n",
    "    #############################\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return model, history, model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b7186-6049-4f0d-b3cc-7b29bf8cc1f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c. Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f566897-048e-4b5b-be2b-0514710252cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_model(X_train, y_train, X_test, y_test, window_size=5, optimizer_name='adam', loss_function='binary_crossentropy', metrics_list=['accuracy'], patience=5, validation_split=0.2, batch_size=64, epochs=100, verbose=1):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    # [1, 5] layers\n",
    "    # nodes per layer [30, 70]\n",
    "    # activation function: relu\n",
    "    # optimizer: Adam\n",
    "    # learning rate = [0.001, 0.1]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = optimizer_name, \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    #############################\n",
    "    #  3 - Training Method  #\n",
    "    #############################\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    #############################\n",
    "    #  4 - Validation Method  #\n",
    "    #############################\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return model, history, model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03624c4-de6e-4068-96f3-1d8f09c8f2f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### d. LSTM Bidirectional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36a8365c-ef38-43c2-83a2-3f1e87f3f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_lstm_model(X_train, y_train, X_test, y_test, window_size=5, optimizer_name='adam', loss_function='binary_crossentropy', metrics_list=['accuracy'], patience=5, validation_split=0.2, batch_size=64, epochs=100, verbose=1):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    \n",
    "    # [1, 5] layers\n",
    "    # nodes per layer [30, 70]\n",
    "    # activation function: relu\n",
    "    # optimizer: Adam\n",
    "    # learning rate = [0.001, 0.1]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(window_size, X_train.shape[-1])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    # $CHALLENGIFY_END\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = optimizer_name, \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    #############################\n",
    "    #  3 - Training Method  #\n",
    "    #############################\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    #############################\n",
    "    #  4 - Validation Method  #\n",
    "    #############################\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    return model, history, model_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ece746-09cc-4e25-bc2a-c65f33828dac",
   "metadata": {},
   "source": [
    "## 4. Model Iterations Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a69d7-810c-4cb3-86dc-0dd441c25397",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. df including only prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4599626b-b945-4536-ab3c-9df810d836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_basline_model(path, formated_df_columns_price, columns_to_drop):\n",
    "    #############################\n",
    "    #  1 - Importing Data       #\n",
    "    #############################\n",
    "    df = import_data(path)\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Basic Formating      #\n",
    "    #############################\n",
    "    formated_df = price_df_formating(df, formated_df_columns_price)\n",
    "    labeled_formated_df = labeling_df(formated_df)\n",
    "    \n",
    "    #############################\n",
    "    #  4 - Preprocessing        #\n",
    "    #############################\n",
    "    clean_merged_df = drop_columns(labeled_formated_df, columns_to_drop)\n",
    "    clean_merged_df = drop_rows(clean_merged_df)\n",
    "    scaled_clean_merged_df = scale_dataframe(clean_merged_df)\n",
    "    split_scaled_clean_merged_df = train_test_split(scaled_clean_merged_df)\n",
    "    X_train, y_train = input_matrix_split_X_y(split_scaled_clean_merged_df[0])\n",
    "    X_test, y_test = input_matrix_split_X_y(split_scaled_clean_merged_df[1])\n",
    "    \n",
    "    #############################\n",
    "    #  5 - Models               #\n",
    "    #############################\n",
    "    baseline_model1 = baseline_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return baseline_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d8630-4f2a-472a-a60e-2fb248039256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. df including only features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "102d157c-68e8-4946-8296-dafc6ed88a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_features_df(path, formated_df_columns):\n",
    "\n",
    "    #############################\n",
    "    #  1 - Importing Data       #\n",
    "    #############################\n",
    "    df = import_data(path)\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Basic Formating      #\n",
    "    #############################\n",
    "    formated_df = df_formating(df, formated_df_columns)\n",
    "    labeled_formated_df = labeling_df(formated_df)\n",
    "    \n",
    "    #############################\n",
    "    #  3 - Feature Engineering  #\n",
    "    #############################\n",
    "    moving_averages(labeled_formated_df)\n",
    "    bollinger_bands(labeled_formated_df)\n",
    "    rdp(labeled_formated_df)\n",
    "    bias(labeled_formated_df)\n",
    "    rsi(labeled_formated_df)\n",
    "    ema(labeled_formated_df)\n",
    "    macd(labeled_formated_df)\n",
    "    psy(labeled_formated_df)\n",
    "    williams_percent_r(labeled_formated_df)\n",
    "    stochastic_oscillator(labeled_formated_df)\n",
    "    proc(labeled_formated_df)\n",
    "    momentum(labeled_formated_df)\n",
    "    first_order_lag(labeled_formated_df)\n",
    "    trading_volume(labeled_formated_df)\n",
    "    \n",
    "    #############################\n",
    "    #  4 - Preprocessing        #\n",
    "    #############################\n",
    "    clean_merged_df = drop_columns(labeled_formated_df)\n",
    "    clean_merged_df = drop_rows(clean_merged_df)\n",
    "    scaled_clean_merged_df = scale_dataframe(clean_merged_df)\n",
    "    split_scaled_clean_merged_df = train_test_split(scaled_clean_merged_df)\n",
    "    X_train, y_train = input_matrix_split_X_y(split_scaled_clean_merged_df[0])\n",
    "    X_test, y_test = input_matrix_split_X_y(split_scaled_clean_merged_df[1])\n",
    "    \n",
    "    #############################\n",
    "    #  5 - Models               #\n",
    "    #############################\n",
    "    f_lstm_model = lstm_model(X_train, y_train, X_test, y_test)\n",
    "    f_gru_model = gru_model(X_train, y_train, X_test, y_test)\n",
    "    f_transformer_model = transformer_model(X_train, y_train, X_test, y_test)\n",
    "    f_bi_lstm_model = bi_lstm_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return f_lstm_model, f_gru_model, f_transformer_model, f_bi_lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757744b2-368b-4065-bb99-bc37b33835be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c. df including features and sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7c32b7b-ecce-4c4d-bb48-89a7539a2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_features_sent_df(path, formated_df_columns, sent_df_columns): \n",
    "\n",
    "    #############################\n",
    "    #  1 - Importing Data       #\n",
    "    #############################\n",
    "    df = import_data(path)\n",
    "    sent_df = import_data_sent(path, sent_df_columns)\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Basic Formating      #\n",
    "    #############################\n",
    "    formated_df = df_formating(df, formated_df_columns)\n",
    "    formated_sent_df = sent_df_formating(sent_df, sent_df_columns)\n",
    "    labeled_formated_df = labeling_df(formated_df)\n",
    "    merged_df = merge_df(labeled_formated_df, formated_sent_df)\n",
    "    \n",
    "    #############################\n",
    "    #  3 - Feature Engineering  #\n",
    "    #############################\n",
    "    moving_averages(merged_df)\n",
    "    bollinger_bands(merged_df)\n",
    "    rdp(merged_df)\n",
    "    bias(merged_df)\n",
    "    rsi(merged_df)\n",
    "    ema(merged_df)\n",
    "    macd(merged_df)\n",
    "    psy(merged_df)\n",
    "    williams_percent_r(merged_df)\n",
    "    stochastic_oscillator(merged_df)\n",
    "    proc(merged_df)\n",
    "    momentum(merged_df)\n",
    "    first_order_lag(merged_df)\n",
    "    trading_volume(merged_df)\n",
    "    \n",
    "    #############################\n",
    "    #  4 - Preprocessing        #\n",
    "    #############################\n",
    "    clean_merged_df = drop_columns(merged_df)\n",
    "    clean_merged_df = drop_rows(clean_merged_df)\n",
    "    scaled_clean_merged_df = scale_dataframe(clean_merged_df)\n",
    "    split_scaled_clean_merged_df = train_test_split(scaled_clean_merged_df)\n",
    "    X_train, y_train = input_matrix_split_X_y(split_scaled_clean_merged_df[0])\n",
    "    X_test, y_test = input_matrix_split_X_y(split_scaled_clean_merged_df[1])\n",
    "    \n",
    "    #############################\n",
    "    #  5 - Models               #\n",
    "    #############################\n",
    "    f_sent_lstm_model = lstm_model(X_train, y_train, X_test, y_test)\n",
    "    f_sent_gru_model = gru_model(X_train, y_train, X_test, y_test)\n",
    "    f_sent_transformer_model = transformer_model(X_train, y_train, X_test, y_test)\n",
    "    f_sent_bi_lstm_model = bi_lstm_model(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return f_sent_lstm_model, f_sent_gru_model, f_sent_transformer_model, f_sent_bi_lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4dc07-3d2f-4841-8735-cc67e3a48017",
   "metadata": {},
   "source": [
    "### d. Visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "623562e9-20dd-467e-b72c-0ad7fbfd1082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n",
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 17ms/step - loss: 0.6942 - accuracy: 0.5121 - val_loss: 0.6937 - val_accuracy: 0.4915\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.5395 - val_loss: 0.6937 - val_accuracy: 0.4915\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5460 - val_loss: 0.6937 - val_accuracy: 0.4915\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6944 - val_accuracy: 0.4836\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5405 - val_loss: 0.6952 - val_accuracy: 0.4706\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5400 - val_loss: 0.6957 - val_accuracy: 0.4726\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5417 - val_loss: 0.6944 - val_accuracy: 0.4866\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5420 - val_loss: 0.6952 - val_accuracy: 0.4726\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n",
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 17ms/step - loss: 0.6978 - accuracy: 0.4947 - val_loss: 0.6942 - val_accuracy: 0.5121\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5221 - val_loss: 0.6957 - val_accuracy: 0.4980\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5261 - val_loss: 0.6981 - val_accuracy: 0.4939\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5299 - val_loss: 0.6991 - val_accuracy: 0.4455\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5437 - val_loss: 0.6979 - val_accuracy: 0.4929\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5449 - val_loss: 0.7004 - val_accuracy: 0.4414\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.6989 - accuracy: 0.4975 - val_loss: 0.6923 - val_accuracy: 0.5343\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5089 - val_loss: 0.6925 - val_accuracy: 0.5505\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5310 - val_loss: 0.6958 - val_accuracy: 0.4798\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5416 - val_loss: 0.7002 - val_accuracy: 0.4657\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5386 - val_loss: 0.7011 - val_accuracy: 0.4697\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5424 - val_loss: 0.6967 - val_accuracy: 0.5020\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 0.6975 - accuracy: 0.5013 - val_loss: 0.6994 - val_accuracy: 0.4525\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5244 - val_loss: 0.7028 - val_accuracy: 0.4465\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5254 - val_loss: 0.7021 - val_accuracy: 0.4616\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5409 - val_loss: 0.7036 - val_accuracy: 0.4586\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5454 - val_loss: 0.7066 - val_accuracy: 0.4192\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5467 - val_loss: 0.7075 - val_accuracy: 0.4455\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 0.6994 - accuracy: 0.4893 - val_loss: 0.6949 - val_accuracy: 0.4909\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5178 - val_loss: 0.6955 - val_accuracy: 0.5051\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5305 - val_loss: 0.6992 - val_accuracy: 0.4687\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5371 - val_loss: 0.6981 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5371 - val_loss: 0.7007 - val_accuracy: 0.4889\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5503 - val_loss: 0.7020 - val_accuracy: 0.4394\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n",
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_75944/241684724.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 16ms/step - loss: 0.7013 - accuracy: 0.4868 - val_loss: 0.6947 - val_accuracy: 0.5202\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5315 - val_loss: 0.6956 - val_accuracy: 0.5182\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5391 - val_loss: 0.6960 - val_accuracy: 0.4990\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5505 - val_loss: 0.6994 - val_accuracy: 0.4596\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5599 - val_loss: 0.7037 - val_accuracy: 0.4525\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5617 - val_loss: 0.7005 - val_accuracy: 0.4838\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.7021 - accuracy: 0.4914 - val_loss: 0.6950 - val_accuracy: 0.4980\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.5228 - val_loss: 0.6931 - val_accuracy: 0.5303\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5269 - val_loss: 0.6977 - val_accuracy: 0.4687\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5421 - val_loss: 0.6977 - val_accuracy: 0.4828\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5541 - val_loss: 0.7000 - val_accuracy: 0.4677\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5482 - val_loss: 0.6993 - val_accuracy: 0.4929\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.5632 - val_loss: 0.6990 - val_accuracy: 0.4980\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.7030 - accuracy: 0.4924 - val_loss: 0.6961 - val_accuracy: 0.4859\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.5208 - val_loss: 0.6957 - val_accuracy: 0.5010\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5284 - val_loss: 0.6967 - val_accuracy: 0.4838\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5320 - val_loss: 0.6955 - val_accuracy: 0.4879\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5492 - val_loss: 0.6960 - val_accuracy: 0.4980\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5497 - val_loss: 0.7015 - val_accuracy: 0.4485\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5652 - val_loss: 0.6997 - val_accuracy: 0.4747\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5612 - val_loss: 0.6983 - val_accuracy: 0.5131\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5673 - val_loss: 0.7035 - val_accuracy: 0.4758\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 17ms/step - loss: 0.7068 - accuracy: 0.4878 - val_loss: 0.6965 - val_accuracy: 0.4949\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5371 - val_loss: 0.6970 - val_accuracy: 0.4717\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5378 - val_loss: 0.7000 - val_accuracy: 0.4626\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5416 - val_loss: 0.7018 - val_accuracy: 0.4505\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.5569 - val_loss: 0.7023 - val_accuracy: 0.4596\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.5510 - val_loss: 0.7038 - val_accuracy: 0.4596\n"
     ]
    }
   ],
   "source": [
    "path = \"cleaned_merged_data-sample-with-sentiment-v02.csv\"\n",
    "formated_df_columns = ['Datetime', 'Open-TSLA', 'High-TSLA', 'Low-TSLA', 'Adj Close-TSLA', 'Volume-TSLA']\n",
    "formated_df_columns_price = ['Datetime','Open-TSLA', 'Adj Close-TSLA']\n",
    "sent_df_columns = ['Datetime', 'score_int', 'total_tweets', 'share_of_positive', 'share_of_negative']\n",
    "columns_to_drop = ['open']\n",
    "\n",
    "base_model, base_history, base_model_acc = pipeline_basline_model(path, formated_df_columns_price, columns_to_drop)\n",
    "\n",
    "\n",
    "f_lstm_model, f_gru_model, f_transformer_model, f_bi_lstm_model = pipeline_features_df(path, formated_df_columns)\n",
    "f_lstm_model, f_lstm_history, f_lstm_model_acc = f_lstm_model\n",
    "f_gru_model, f_gru_history, f_gru_model_acc = f_gru_model\n",
    "f_trans_model, f_trans_history, f_trans_model_acc = f_transformer_model\n",
    "f_bi_lstm_model, f_bi_lstm_history, f_bi_lstm_model_acc = f_bi_lstm_model\n",
    "\n",
    "\n",
    "f_sent_lstm_model, f_sent_gru_model, f_sent_transformer_model, f_sent_bi_lstm_model = pipeline_features_sent_df(path, formated_df_columns, sent_df_columns)\n",
    "f_sent_lstm_model, f_sent_lstm_history, f_sent_lstm_model_acc = f_sent_lstm_model\n",
    "f_sent_gru_model, f_sent_gru_history, f_sent_gru_model_acc = f_sent_gru_model\n",
    "f_sent_trans_model, f_sent_trans_history, f_sent_trans_model_acc = f_sent_transformer_model\n",
    "f_sent_bi_lstm_model, f_sent_bi_lstm_history, f_sent_bi_lstm_model_acc = f_sent_bi_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8137910-e122-41d9-a45b-d400f6634525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "history = train_model()\n",
    "print(f'Model Accuracy {model_acc[1]:.4f}')\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2827e7-2e8a-4f8e-8e25-d059b94fe39c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5 Model Optimisation template idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53027725-e2d3-42d6-98c0-617df3e67f3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47f75f82-8fe8-478b-a6eb-3ac083a5b607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 8.11 µs\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 1.0806 - accuracy: 0.5213 - val_loss: 0.7726 - val_accuracy: 0.5192 - 541ms/epoch - 42ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 0.7574 - accuracy: 0.5038 - val_loss: 0.8236 - val_accuracy: 0.4727 - 37ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 0.7194 - accuracy: 0.5574 - val_loss: 0.8042 - val_accuracy: 0.4646 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 0.7013 - accuracy: 0.5475 - val_loss: 0.8665 - val_accuracy: 0.4707 - 34ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 0.6886 - accuracy: 0.5584 - val_loss: 0.7436 - val_accuracy: 0.5010 - 36ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 0.6862 - accuracy: 0.5589 - val_loss: 0.7549 - val_accuracy: 0.4859 - 35ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 0.6754 - accuracy: 0.5652 - val_loss: 0.7561 - val_accuracy: 0.4778 - 34ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "13/13 - 0s - loss: 0.6711 - accuracy: 0.5525 - val_loss: 0.7857 - val_accuracy: 0.4717 - 33ms/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "13/13 - 0s - loss: 0.6601 - accuracy: 0.5939 - val_loss: 0.7891 - val_accuracy: 0.5051 - 33ms/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "13/13 - 0s - loss: 0.6724 - accuracy: 0.5931 - val_loss: 0.7990 - val_accuracy: 0.5010 - 36ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 1.1214 - accuracy: 0.4985 - val_loss: 0.8895 - val_accuracy: 0.5152 - 564ms/epoch - 43ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 0.7442 - accuracy: 0.5178 - val_loss: 1.0395 - val_accuracy: 0.4768 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 0.7109 - accuracy: 0.5467 - val_loss: 0.8592 - val_accuracy: 0.4919 - 34ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 0.6868 - accuracy: 0.5541 - val_loss: 0.7801 - val_accuracy: 0.5040 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 0.6974 - accuracy: 0.5683 - val_loss: 0.7546 - val_accuracy: 0.5061 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 0.6833 - accuracy: 0.5556 - val_loss: 0.7828 - val_accuracy: 0.4970 - 34ms/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "13/13 - 0s - loss: 0.6846 - accuracy: 0.5602 - val_loss: 0.8360 - val_accuracy: 0.4889 - 34ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "13/13 - 0s - loss: 0.6668 - accuracy: 0.6033 - val_loss: 0.8499 - val_accuracy: 0.5040 - 34ms/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "13/13 - 0s - loss: 0.6605 - accuracy: 0.5863 - val_loss: 0.8617 - val_accuracy: 0.5111 - 31ms/epoch - 2ms/step\n",
      "Epoch 10/60\n",
      "13/13 - 0s - loss: 0.6528 - accuracy: 0.6127 - val_loss: 0.8029 - val_accuracy: 0.5071 - 33ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 1.1236 - accuracy: 0.4929 - val_loss: 0.7779 - val_accuracy: 0.4970 - 549ms/epoch - 42ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 0.7476 - accuracy: 0.5259 - val_loss: 1.0313 - val_accuracy: 0.4747 - 36ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 0.7107 - accuracy: 0.5297 - val_loss: 0.7116 - val_accuracy: 0.4970 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 0.6905 - accuracy: 0.5434 - val_loss: 0.7182 - val_accuracy: 0.4737 - 34ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 0.6824 - accuracy: 0.5723 - val_loss: 0.7595 - val_accuracy: 0.4828 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 0.6871 - accuracy: 0.5558 - val_loss: 0.8009 - val_accuracy: 0.4747 - 35ms/epoch - 3ms/step\n",
      "Epoch 7/70\n",
      "13/13 - 0s - loss: 0.6677 - accuracy: 0.5860 - val_loss: 0.8883 - val_accuracy: 0.4717 - 35ms/epoch - 3ms/step\n",
      "Epoch 8/70\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.5807 - val_loss: 0.8100 - val_accuracy: 0.4879 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 1.1461 - accuracy: 0.5173 - val_loss: 0.7727 - val_accuracy: 0.4616 - 644ms/epoch - 50ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 0.7217 - accuracy: 0.5183 - val_loss: 0.7462 - val_accuracy: 0.5091 - 36ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 0.7009 - accuracy: 0.5287 - val_loss: 0.7590 - val_accuracy: 0.4758 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 0.6815 - accuracy: 0.5622 - val_loss: 0.7422 - val_accuracy: 0.5182 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 0.6736 - accuracy: 0.5855 - val_loss: 0.7603 - val_accuracy: 0.5061 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 0.6855 - accuracy: 0.5726 - val_loss: 0.8070 - val_accuracy: 0.4838 - 35ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 0.6723 - accuracy: 0.5820 - val_loss: 0.8386 - val_accuracy: 0.5040 - 36ms/epoch - 3ms/step\n",
      "Epoch 8/80\n",
      "13/13 - 0s - loss: 0.6823 - accuracy: 0.5997 - val_loss: 0.8715 - val_accuracy: 0.5040 - 33ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "13/13 - 0s - loss: 0.7111 - accuracy: 0.5759 - val_loss: 0.8519 - val_accuracy: 0.5071 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 7.1872 - accuracy: 0.4934 - val_loss: 7.9262 - val_accuracy: 0.4838 - 537ms/epoch - 41ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.4225 - accuracy: 0.5147 - val_loss: 7.7022 - val_accuracy: 0.4970 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.6468 - accuracy: 0.4992 - val_loss: 7.7363 - val_accuracy: 0.4939 - 37ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2459 - accuracy: 0.5282 - val_loss: 8.1321 - val_accuracy: 0.4717 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2203 - accuracy: 0.5312 - val_loss: 8.2778 - val_accuracy: 0.4626 - 35ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.4258 - accuracy: 0.5152 - val_loss: 7.3152 - val_accuracy: 0.5212 - 35ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 7.8855 - accuracy: 0.4840 - val_loss: 7.2616 - val_accuracy: 0.5242 - 36ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "13/13 - 0s - loss: 7.9365 - accuracy: 0.4807 - val_loss: 7.3148 - val_accuracy: 0.5212 - 32ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "13/13 - 0s - loss: 7.9196 - accuracy: 0.4817 - val_loss: 7.4687 - val_accuracy: 0.5111 - 33ms/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "13/13 - 0s - loss: 7.8859 - accuracy: 0.4838 - val_loss: 7.3258 - val_accuracy: 0.5202 - 33ms/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "13/13 - 0s - loss: 7.8578 - accuracy: 0.4858 - val_loss: 7.3568 - val_accuracy: 0.5182 - 33ms/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "13/13 - 0s - loss: 7.8621 - accuracy: 0.4853 - val_loss: 7.3106 - val_accuracy: 0.5212 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.5621 - accuracy: 0.4650 - val_loss: 7.1625 - val_accuracy: 0.5303 - 530ms/epoch - 41ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.1045 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 8.1045 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 8.1045 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 8.1045 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 8.1045 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.7955 - accuracy: 0.5132 - val_loss: 8.1799 - val_accuracy: 0.4697 - 528ms/epoch - 41ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 33ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 7.1833 - accuracy: 0.5005 - val_loss: 7.7023 - val_accuracy: 0.4980 - 535ms/epoch - 41ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.5901 - accuracy: 0.5061 - val_loss: 7.8797 - val_accuracy: 0.4869 - 33ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.3651 - accuracy: 0.5213 - val_loss: 8.0078 - val_accuracy: 0.4798 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.2966 - accuracy: 0.5261 - val_loss: 7.9200 - val_accuracy: 0.4859 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.2945 - accuracy: 0.5266 - val_loss: 7.9832 - val_accuracy: 0.4818 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.3216 - accuracy: 0.5249 - val_loss: 7.9838 - val_accuracy: 0.4818 - 35ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 7.4669 - accuracy: 0.4784 - val_loss: 7.1625 - val_accuracy: 0.5303 - 535ms/epoch - 41ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 33ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.4662 - accuracy: 0.4731 - val_loss: 7.1957 - val_accuracy: 0.5283 - 531ms/epoch - 41ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.0816 - accuracy: 0.4701 - val_loss: 7.2107 - val_accuracy: 0.5273 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 8.0816 - accuracy: 0.4701 - val_loss: 7.2263 - val_accuracy: 0.5263 - 34ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 8.0420 - accuracy: 0.4723 - val_loss: 7.3446 - val_accuracy: 0.5192 - 34ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 8.0377 - accuracy: 0.4734 - val_loss: 7.2840 - val_accuracy: 0.5232 - 35ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 7.9223 - accuracy: 0.4810 - val_loss: 7.3619 - val_accuracy: 0.5182 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 7.5691 - accuracy: 0.4657 - val_loss: 7.1625 - val_accuracy: 0.5303 - 686ms/epoch - 53ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 8.1162 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 8.1162 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 8.1162 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 8.1162 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 8.1162 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 6.7474 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 533ms/epoch - 41ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 36ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 1.4287 - accuracy: 0.4698 - val_loss: 0.8409 - val_accuracy: 0.5020 - 523ms/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 0.7636 - accuracy: 0.5310 - val_loss: 0.9648 - val_accuracy: 0.4636 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 0.7229 - accuracy: 0.5404 - val_loss: 0.8390 - val_accuracy: 0.4798 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 0.7051 - accuracy: 0.5348 - val_loss: 0.8636 - val_accuracy: 0.4838 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 0.6854 - accuracy: 0.5508 - val_loss: 0.7881 - val_accuracy: 0.4990 - 27ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 0.6964 - accuracy: 0.5543 - val_loss: 0.8377 - val_accuracy: 0.4879 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "7/7 - 0s - loss: 0.6796 - accuracy: 0.5698 - val_loss: 0.8885 - val_accuracy: 0.4657 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/50\n",
      "7/7 - 0s - loss: 0.6705 - accuracy: 0.5789 - val_loss: 0.8962 - val_accuracy: 0.4576 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "7/7 - 0s - loss: 0.6804 - accuracy: 0.5581 - val_loss: 0.8432 - val_accuracy: 0.4677 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/50\n",
      "7/7 - 0s - loss: 0.6591 - accuracy: 0.5972 - val_loss: 0.8302 - val_accuracy: 0.4939 - 29ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 1.7083 - accuracy: 0.4901 - val_loss: 1.0909 - val_accuracy: 0.4788 - 520ms/epoch - 74ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 0.7785 - accuracy: 0.5183 - val_loss: 0.8263 - val_accuracy: 0.4636 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 0.7227 - accuracy: 0.5373 - val_loss: 0.8953 - val_accuracy: 0.4768 - 27ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 0.7178 - accuracy: 0.5165 - val_loss: 0.8545 - val_accuracy: 0.4586 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 0.7241 - accuracy: 0.5345 - val_loss: 0.8829 - val_accuracy: 0.4616 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 0.6806 - accuracy: 0.5685 - val_loss: 0.8037 - val_accuracy: 0.4747 - 27ms/epoch - 4ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 0.6791 - accuracy: 0.5690 - val_loss: 0.8131 - val_accuracy: 0.4848 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/60\n",
      "7/7 - 0s - loss: 0.6717 - accuracy: 0.5645 - val_loss: 0.8466 - val_accuracy: 0.4929 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/60\n",
      "7/7 - 0s - loss: 0.6520 - accuracy: 0.6003 - val_loss: 0.9014 - val_accuracy: 0.4717 - 28ms/epoch - 4ms/step\n",
      "Epoch 10/60\n",
      "7/7 - 0s - loss: 0.6561 - accuracy: 0.6038 - val_loss: 0.9573 - val_accuracy: 0.4859 - 29ms/epoch - 4ms/step\n",
      "Epoch 11/60\n",
      "7/7 - 0s - loss: 0.6651 - accuracy: 0.5995 - val_loss: 0.9571 - val_accuracy: 0.4717 - 28ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 1.5310 - accuracy: 0.4952 - val_loss: 1.0617 - val_accuracy: 0.5283 - 521ms/epoch - 74ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 0.8074 - accuracy: 0.5063 - val_loss: 0.9667 - val_accuracy: 0.4636 - 26ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 0.7351 - accuracy: 0.5335 - val_loss: 0.7724 - val_accuracy: 0.5040 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 0.6970 - accuracy: 0.5383 - val_loss: 0.7539 - val_accuracy: 0.4909 - 27ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 0.6919 - accuracy: 0.5393 - val_loss: 0.8189 - val_accuracy: 0.4990 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 0.6908 - accuracy: 0.5632 - val_loss: 0.7868 - val_accuracy: 0.4899 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 0.6734 - accuracy: 0.5916 - val_loss: 0.8413 - val_accuracy: 0.4848 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/70\n",
      "7/7 - 0s - loss: 0.6670 - accuracy: 0.5807 - val_loss: 0.8552 - val_accuracy: 0.4929 - 26ms/epoch - 4ms/step\n",
      "Epoch 9/70\n",
      "7/7 - 0s - loss: 0.6699 - accuracy: 0.5807 - val_loss: 0.9416 - val_accuracy: 0.5162 - 27ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_17 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 1.7640 - accuracy: 0.5071 - val_loss: 0.7180 - val_accuracy: 0.4889 - 525ms/epoch - 75ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 0.7241 - accuracy: 0.5426 - val_loss: 0.7973 - val_accuracy: 0.4909 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 0.7261 - accuracy: 0.5320 - val_loss: 0.8286 - val_accuracy: 0.4929 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 0.6922 - accuracy: 0.5541 - val_loss: 0.8655 - val_accuracy: 0.4899 - 27ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 0.7319 - accuracy: 0.5543 - val_loss: 0.8412 - val_accuracy: 0.4949 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 0.6801 - accuracy: 0.5657 - val_loss: 0.8230 - val_accuracy: 0.4838 - 29ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.0370 - accuracy: 0.5254 - val_loss: 7.8916 - val_accuracy: 0.4848 - 531ms/epoch - 76ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.2469 - accuracy: 0.5294 - val_loss: 8.0330 - val_accuracy: 0.4778 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.2588 - accuracy: 0.5292 - val_loss: 7.9506 - val_accuracy: 0.4838 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.2398 - accuracy: 0.5305 - val_loss: 7.9870 - val_accuracy: 0.4808 - 32ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.2473 - accuracy: 0.5299 - val_loss: 7.9795 - val_accuracy: 0.4818 - 37ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.2392 - accuracy: 0.5305 - val_loss: 7.9786 - val_accuracy: 0.4818 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 6.1626 - accuracy: 0.5190 - val_loss: 8.0934 - val_accuracy: 0.4747 - 524ms/epoch - 75ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.1906 - accuracy: 0.5338 - val_loss: 8.1625 - val_accuracy: 0.4697 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.1829 - accuracy: 0.5340 - val_loss: 8.0813 - val_accuracy: 0.4758 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.2223 - accuracy: 0.5315 - val_loss: 8.0502 - val_accuracy: 0.4778 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.1892 - accuracy: 0.5335 - val_loss: 8.0599 - val_accuracy: 0.4768 - 27ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.2154 - accuracy: 0.5320 - val_loss: 8.0811 - val_accuracy: 0.4758 - 29ms/epoch - 4ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 7.2052 - accuracy: 0.5325 - val_loss: 8.0981 - val_accuracy: 0.4747 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/60\n",
      "7/7 - 0s - loss: 7.1826 - accuracy: 0.5338 - val_loss: 8.0197 - val_accuracy: 0.4798 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/60\n",
      "7/7 - 0s - loss: 7.1936 - accuracy: 0.5335 - val_loss: 8.0659 - val_accuracy: 0.4768 - 29ms/epoch - 4ms/step\n",
      "Epoch 10/60\n",
      "7/7 - 0s - loss: 7.1943 - accuracy: 0.5335 - val_loss: 8.0292 - val_accuracy: 0.4788 - 27ms/epoch - 4ms/step\n",
      "Epoch 11/60\n",
      "7/7 - 0s - loss: 7.1954 - accuracy: 0.5330 - val_loss: 8.0818 - val_accuracy: 0.4758 - 28ms/epoch - 4ms/step\n",
      "Epoch 12/60\n",
      "7/7 - 0s - loss: 7.2065 - accuracy: 0.5327 - val_loss: 8.0363 - val_accuracy: 0.4788 - 28ms/epoch - 4ms/step\n",
      "Epoch 13/60\n",
      "7/7 - 0s - loss: 7.2227 - accuracy: 0.5317 - val_loss: 8.0993 - val_accuracy: 0.4747 - 27ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 7.0452 - accuracy: 0.4607 - val_loss: 7.1625 - val_accuracy: 0.5303 - 690ms/epoch - 99ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 27ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 28ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 6.0868 - accuracy: 0.5277 - val_loss: 8.1799 - val_accuracy: 0.4697 - 526ms/epoch - 75ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 27ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.2743 - accuracy: 0.5061 - val_loss: 8.2440 - val_accuracy: 0.4646 - 522ms/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.3103 - accuracy: 0.5256 - val_loss: 8.2192 - val_accuracy: 0.4667 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.3526 - accuracy: 0.5228 - val_loss: 8.1875 - val_accuracy: 0.4687 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.3639 - accuracy: 0.5221 - val_loss: 8.2024 - val_accuracy: 0.4677 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.3404 - accuracy: 0.5236 - val_loss: 8.2024 - val_accuracy: 0.4677 - 28ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.3366 - accuracy: 0.5239 - val_loss: 8.2024 - val_accuracy: 0.4677 - 26ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "7/7 - 0s - loss: 7.3366 - accuracy: 0.5239 - val_loss: 8.2024 - val_accuracy: 0.4677 - 27ms/epoch - 4ms/step\n",
      "Epoch 8/50\n",
      "7/7 - 0s - loss: 7.3366 - accuracy: 0.5239 - val_loss: 8.2024 - val_accuracy: 0.4677 - 27ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 7.1184 - accuracy: 0.4480 - val_loss: 7.1625 - val_accuracy: 0.5303 - 555ms/epoch - 79ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 8.1472 - accuracy: 0.4657 - val_loss: 7.1625 - val_accuracy: 0.5303 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 8.0010 - accuracy: 0.4756 - val_loss: 7.1625 - val_accuracy: 0.5303 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 8.0102 - accuracy: 0.4749 - val_loss: 7.1625 - val_accuracy: 0.5303 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 8.0747 - accuracy: 0.4706 - val_loss: 7.1625 - val_accuracy: 0.5303 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 8.1057 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 27ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 6.6602 - accuracy: 0.4952 - val_loss: 7.2266 - val_accuracy: 0.5263 - 527ms/epoch - 75ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.1953 - accuracy: 0.5294 - val_loss: 7.1960 - val_accuracy: 0.5283 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.2558 - accuracy: 0.5261 - val_loss: 7.2337 - val_accuracy: 0.5263 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.2810 - accuracy: 0.5274 - val_loss: 8.0726 - val_accuracy: 0.4758 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.2442 - accuracy: 0.5302 - val_loss: 8.1349 - val_accuracy: 0.4717 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.2404 - accuracy: 0.5305 - val_loss: 8.1194 - val_accuracy: 0.4727 - 27ms/epoch - 4ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 7.2283 - accuracy: 0.5310 - val_loss: 7.9932 - val_accuracy: 0.4808 - 27ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_25 (LSTM)              (None, 5, 50)             15600     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 5, 1)              51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15651 (61.14 KB)\n",
      "Trainable params: 15651 (61.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 6.3723 - accuracy: 0.5297 - val_loss: 8.1792 - val_accuracy: 0.4697 - 556ms/epoch - 79ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 7.2754 - accuracy: 0.5279 - val_loss: 8.2254 - val_accuracy: 0.4667 - 28ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 7.2678 - accuracy: 0.5284 - val_loss: 8.1631 - val_accuracy: 0.4707 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 7.2943 - accuracy: 0.5266 - val_loss: 8.1629 - val_accuracy: 0.4707 - 28ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 7.3123 - accuracy: 0.5254 - val_loss: 8.1787 - val_accuracy: 0.4697 - 26ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 7.3312 - accuracy: 0.5241 - val_loss: 8.2098 - val_accuracy: 0.4677 - 28ms/epoch - 4ms/step\n",
      "Epoch 7/80\n",
      "7/7 - 0s - loss: 7.3302 - accuracy: 0.5241 - val_loss: 8.1636 - val_accuracy: 0.4707 - 28ms/epoch - 4ms/step\n",
      "Epoch 8/80\n",
      "7/7 - 0s - loss: 7.3336 - accuracy: 0.5239 - val_loss: 8.1636 - val_accuracy: 0.4707 - 28ms/epoch - 4ms/step\n",
      "Epoch 9/80\n",
      "7/7 - 0s - loss: 7.3257 - accuracy: 0.5244 - val_loss: 8.1636 - val_accuracy: 0.4707 - 26ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 1.3466 - accuracy: 0.5056 - val_loss: 0.8661 - val_accuracy: 0.5192 - 557ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 0.7432 - accuracy: 0.5066 - val_loss: 0.7566 - val_accuracy: 0.4828 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 0.7364 - accuracy: 0.5269 - val_loss: 0.7333 - val_accuracy: 0.4838 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 0.7104 - accuracy: 0.5246 - val_loss: 0.7355 - val_accuracy: 0.4859 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 0.6866 - accuracy: 0.5662 - val_loss: 0.8266 - val_accuracy: 0.4808 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 0.6851 - accuracy: 0.5619 - val_loss: 0.9148 - val_accuracy: 0.4626 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 0.6989 - accuracy: 0.5589 - val_loss: 0.7990 - val_accuracy: 0.4929 - 39ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "13/13 - 0s - loss: 0.7034 - accuracy: 0.5419 - val_loss: 0.7211 - val_accuracy: 0.5121 - 37ms/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "13/13 - 0s - loss: 0.6910 - accuracy: 0.5467 - val_loss: 0.8302 - val_accuracy: 0.4636 - 38ms/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "13/13 - 0s - loss: 0.6908 - accuracy: 0.5594 - val_loss: 0.8056 - val_accuracy: 0.5020 - 38ms/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "13/13 - 0s - loss: 0.6756 - accuracy: 0.5807 - val_loss: 0.7854 - val_accuracy: 0.4939 - 36ms/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "13/13 - 0s - loss: 0.6631 - accuracy: 0.5909 - val_loss: 0.8148 - val_accuracy: 0.4788 - 38ms/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "13/13 - 0s - loss: 0.6554 - accuracy: 0.6152 - val_loss: 1.0902 - val_accuracy: 0.5051 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_27 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 1.3442 - accuracy: 0.5254 - val_loss: 0.7586 - val_accuracy: 0.5091 - 561ms/epoch - 43ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 0.7724 - accuracy: 0.5251 - val_loss: 0.8601 - val_accuracy: 0.4970 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 0.7091 - accuracy: 0.5421 - val_loss: 0.7806 - val_accuracy: 0.5101 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 0.7084 - accuracy: 0.5525 - val_loss: 0.8908 - val_accuracy: 0.4788 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 0.6894 - accuracy: 0.5632 - val_loss: 1.2526 - val_accuracy: 0.4747 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 0.6802 - accuracy: 0.5883 - val_loss: 0.8251 - val_accuracy: 0.4960 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 1.3142 - accuracy: 0.5135 - val_loss: 0.7640 - val_accuracy: 0.5333 - 553ms/epoch - 43ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 0.7511 - accuracy: 0.5183 - val_loss: 0.8730 - val_accuracy: 0.4596 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 0.7137 - accuracy: 0.5650 - val_loss: 0.9296 - val_accuracy: 0.4707 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 0.7060 - accuracy: 0.5353 - val_loss: 0.8008 - val_accuracy: 0.4747 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 0.6748 - accuracy: 0.5632 - val_loss: 0.8653 - val_accuracy: 0.4697 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 0.6669 - accuracy: 0.5888 - val_loss: 0.8916 - val_accuracy: 0.4859 - 38ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_29 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 1.2771 - accuracy: 0.5079 - val_loss: 0.8388 - val_accuracy: 0.5202 - 739ms/epoch - 57ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 0.7802 - accuracy: 0.5211 - val_loss: 0.7250 - val_accuracy: 0.5091 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 0.7203 - accuracy: 0.5338 - val_loss: 0.8588 - val_accuracy: 0.4475 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 0.6959 - accuracy: 0.5480 - val_loss: 0.7325 - val_accuracy: 0.5202 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 0.6692 - accuracy: 0.5711 - val_loss: 0.7664 - val_accuracy: 0.4818 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 0.6752 - accuracy: 0.5840 - val_loss: 0.7777 - val_accuracy: 0.4778 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 0.6832 - accuracy: 0.5761 - val_loss: 0.7867 - val_accuracy: 0.5000 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 6.6273 - accuracy: 0.5327 - val_loss: 8.1799 - val_accuracy: 0.4697 - 563ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.2269 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.2269 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2269 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2269 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 37ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.2269 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 38ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_31 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.4919 - accuracy: 0.4728 - val_loss: 7.1625 - val_accuracy: 0.5303 - 552ms/epoch - 42ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.1063 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 46ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 7.9678 - accuracy: 0.4777 - val_loss: 7.1482 - val_accuracy: 0.5313 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 8.0009 - accuracy: 0.4756 - val_loss: 7.1174 - val_accuracy: 0.5333 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 8.0014 - accuracy: 0.4756 - val_loss: 7.1020 - val_accuracy: 0.5343 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 8.0094 - accuracy: 0.4751 - val_loss: 7.1176 - val_accuracy: 0.5333 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "13/13 - 0s - loss: 8.0055 - accuracy: 0.4754 - val_loss: 7.1020 - val_accuracy: 0.5343 - 40ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "13/13 - 0s - loss: 7.9938 - accuracy: 0.4761 - val_loss: 7.1020 - val_accuracy: 0.5343 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "13/13 - 0s - loss: 7.9977 - accuracy: 0.4759 - val_loss: 7.1020 - val_accuracy: 0.5343 - 40ms/epoch - 3ms/step\n",
      "Epoch 10/60\n",
      "13/13 - 0s - loss: 7.9977 - accuracy: 0.4759 - val_loss: 7.1020 - val_accuracy: 0.5343 - 37ms/epoch - 3ms/step\n",
      "Epoch 11/60\n",
      "13/13 - 0s - loss: 7.9977 - accuracy: 0.4759 - val_loss: 7.1020 - val_accuracy: 0.5343 - 39ms/epoch - 3ms/step\n",
      "Epoch 12/60\n",
      "13/13 - 0s - loss: 7.9977 - accuracy: 0.4759 - val_loss: 7.1020 - val_accuracy: 0.5343 - 39ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 7.6611 - accuracy: 0.4673 - val_loss: 7.1625 - val_accuracy: 0.5303 - 539ms/epoch - 41ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 37ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_33 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 6.8754 - accuracy: 0.5195 - val_loss: 8.1470 - val_accuracy: 0.4717 - 533ms/epoch - 41ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.2699 - accuracy: 0.5277 - val_loss: 8.1944 - val_accuracy: 0.4687 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.2453 - accuracy: 0.5297 - val_loss: 8.1301 - val_accuracy: 0.4727 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.1867 - accuracy: 0.5335 - val_loss: 8.1762 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1450 - val_accuracy: 0.4717 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 37ms/epoch - 3ms/step\n",
      "Epoch 8/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 39ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 39ms/epoch - 3ms/step\n",
      "Epoch 10/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 40ms/epoch - 3ms/step\n",
      "Epoch 11/80\n",
      "13/13 - 0s - loss: 7.1750 - accuracy: 0.5343 - val_loss: 8.1294 - val_accuracy: 0.4727 - 39ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 6.8138 - accuracy: 0.5297 - val_loss: 8.1799 - val_accuracy: 0.4697 - 572ms/epoch - 44ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.2265 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.2265 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2265 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2265 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.2265 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_35 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.5026 - accuracy: 0.4759 - val_loss: 7.1625 - val_accuracy: 0.5303 - 531ms/epoch - 41ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.1712 - accuracy: 0.4642 - val_loss: 7.1625 - val_accuracy: 0.5303 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 8.1282 - accuracy: 0.4680 - val_loss: 7.1625 - val_accuracy: 0.5303 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 7.5002 - accuracy: 0.5109 - val_loss: 7.0708 - val_accuracy: 0.5364 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 7.4918 - accuracy: 0.5117 - val_loss: 7.0866 - val_accuracy: 0.5354 - 58ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 7.5007 - accuracy: 0.5112 - val_loss: 7.0867 - val_accuracy: 0.5354 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "13/13 - 0s - loss: 7.5087 - accuracy: 0.5107 - val_loss: 7.0713 - val_accuracy: 0.5364 - 39ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "13/13 - 0s - loss: 7.5126 - accuracy: 0.5104 - val_loss: 7.0713 - val_accuracy: 0.5364 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "13/13 - 0s - loss: 7.5165 - accuracy: 0.5102 - val_loss: 7.0715 - val_accuracy: 0.5364 - 37ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.7467 - accuracy: 0.5282 - val_loss: 8.1487 - val_accuracy: 0.4717 - 540ms/epoch - 42ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.2096 - accuracy: 0.5322 - val_loss: 8.1084 - val_accuracy: 0.4737 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.2266 - accuracy: 0.5310 - val_loss: 8.1013 - val_accuracy: 0.4737 - 38ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.2081 - accuracy: 0.5325 - val_loss: 8.1636 - val_accuracy: 0.4707 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.2478 - accuracy: 0.5299 - val_loss: 8.1636 - val_accuracy: 0.4707 - 40ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.2441 - accuracy: 0.5302 - val_loss: 8.1636 - val_accuracy: 0.4707 - 41ms/epoch - 3ms/step\n",
      "Epoch 7/70\n",
      "13/13 - 0s - loss: 7.2441 - accuracy: 0.5302 - val_loss: 8.1636 - val_accuracy: 0.4707 - 41ms/epoch - 3ms/step\n",
      "Epoch 8/70\n",
      "13/13 - 0s - loss: 7.2441 - accuracy: 0.5302 - val_loss: 8.1636 - val_accuracy: 0.4707 - 42ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_37 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 6.6555 - accuracy: 0.5353 - val_loss: 8.1799 - val_accuracy: 0.4697 - 541ms/epoch - 42ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 39ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 1.8168 - accuracy: 0.4865 - val_loss: 0.7726 - val_accuracy: 0.5000 - 549ms/epoch - 78ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 0.7540 - accuracy: 0.5175 - val_loss: 0.8634 - val_accuracy: 0.4859 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 0.7263 - accuracy: 0.5231 - val_loss: 0.8074 - val_accuracy: 0.4808 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 0.7192 - accuracy: 0.5178 - val_loss: 0.8567 - val_accuracy: 0.5040 - 31ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 0.7054 - accuracy: 0.5467 - val_loss: 1.2247 - val_accuracy: 0.5071 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 0.7211 - accuracy: 0.5551 - val_loss: 0.8668 - val_accuracy: 0.5121 - 31ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_39 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 2.2307 - accuracy: 0.4980 - val_loss: 0.8185 - val_accuracy: 0.5152 - 535ms/epoch - 76ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 0.7687 - accuracy: 0.5289 - val_loss: 0.9379 - val_accuracy: 0.4929 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 0.7438 - accuracy: 0.5317 - val_loss: 0.7729 - val_accuracy: 0.5263 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 0.7072 - accuracy: 0.5614 - val_loss: 0.8680 - val_accuracy: 0.4960 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 0.6743 - accuracy: 0.5924 - val_loss: 0.8093 - val_accuracy: 0.5242 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 0.6580 - accuracy: 0.5997 - val_loss: 0.8424 - val_accuracy: 0.4737 - 31ms/epoch - 4ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 0.6707 - accuracy: 0.5914 - val_loss: 0.8048 - val_accuracy: 0.5253 - 31ms/epoch - 4ms/step\n",
      "Epoch 8/60\n",
      "7/7 - 0s - loss: 0.6449 - accuracy: 0.6152 - val_loss: 0.9058 - val_accuracy: 0.5111 - 31ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 2.1406 - accuracy: 0.5069 - val_loss: 1.3251 - val_accuracy: 0.4677 - 772ms/epoch - 110ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 0.8474 - accuracy: 0.5327 - val_loss: 0.8141 - val_accuracy: 0.5182 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 0.7396 - accuracy: 0.5168 - val_loss: 0.9092 - val_accuracy: 0.4717 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 0.7351 - accuracy: 0.5322 - val_loss: 0.7700 - val_accuracy: 0.5071 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 0.7040 - accuracy: 0.5439 - val_loss: 1.0431 - val_accuracy: 0.5273 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 0.7260 - accuracy: 0.5368 - val_loss: 0.7910 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 0.6899 - accuracy: 0.5728 - val_loss: 0.7452 - val_accuracy: 0.5040 - 29ms/epoch - 4ms/step\n",
      "Epoch 8/70\n",
      "7/7 - 0s - loss: 0.6662 - accuracy: 0.5962 - val_loss: 0.8178 - val_accuracy: 0.5374 - 31ms/epoch - 4ms/step\n",
      "Epoch 9/70\n",
      "7/7 - 0s - loss: 0.6675 - accuracy: 0.5926 - val_loss: 0.8239 - val_accuracy: 0.4859 - 31ms/epoch - 4ms/step\n",
      "Epoch 10/70\n",
      "7/7 - 0s - loss: 0.6555 - accuracy: 0.6183 - val_loss: 0.8488 - val_accuracy: 0.4980 - 28ms/epoch - 4ms/step\n",
      "Epoch 11/70\n",
      "7/7 - 0s - loss: 0.6305 - accuracy: 0.6307 - val_loss: 0.8624 - val_accuracy: 0.5091 - 32ms/epoch - 5ms/step\n",
      "Epoch 12/70\n",
      "7/7 - 0s - loss: 0.6491 - accuracy: 0.6223 - val_loss: 0.9142 - val_accuracy: 0.5172 - 31ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_41 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 1.7422 - accuracy: 0.4980 - val_loss: 0.7513 - val_accuracy: 0.4838 - 540ms/epoch - 77ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 0.7452 - accuracy: 0.5132 - val_loss: 0.8185 - val_accuracy: 0.4899 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 0.7293 - accuracy: 0.5307 - val_loss: 0.7744 - val_accuracy: 0.4859 - 28ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 0.7163 - accuracy: 0.5518 - val_loss: 0.9589 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 0.7790 - accuracy: 0.5332 - val_loss: 0.8361 - val_accuracy: 0.4576 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 0.7061 - accuracy: 0.5485 - val_loss: 0.8975 - val_accuracy: 0.4879 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_42 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.1620 - accuracy: 0.5244 - val_loss: 8.1799 - val_accuracy: 0.4697 - 547ms/epoch - 78ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_43 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 5.9853 - accuracy: 0.5452 - val_loss: 8.1799 - val_accuracy: 0.4697 - 534ms/epoch - 76ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 7.0471 - accuracy: 0.4541 - val_loss: 7.2406 - val_accuracy: 0.5253 - 549ms/epoch - 78ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.8800 - accuracy: 0.4835 - val_loss: 7.3713 - val_accuracy: 0.5162 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.9771 - accuracy: 0.4772 - val_loss: 7.2061 - val_accuracy: 0.5273 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.9640 - accuracy: 0.4782 - val_loss: 7.3479 - val_accuracy: 0.5182 - 30ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.9579 - accuracy: 0.4784 - val_loss: 7.2751 - val_accuracy: 0.5232 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.9953 - accuracy: 0.4761 - val_loss: 7.2504 - val_accuracy: 0.5253 - 31ms/epoch - 4ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 7.9851 - accuracy: 0.4769 - val_loss: 7.3428 - val_accuracy: 0.5192 - 32ms/epoch - 5ms/step\n",
      "Epoch 8/70\n",
      "7/7 - 0s - loss: 7.9684 - accuracy: 0.4779 - val_loss: 7.3426 - val_accuracy: 0.5192 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_45 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 7.0412 - accuracy: 0.4670 - val_loss: 7.1625 - val_accuracy: 0.5303 - 527ms/epoch - 75ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 33ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.1330 - accuracy: 0.5368 - val_loss: 8.1799 - val_accuracy: 0.4697 - 554ms/epoch - 79ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.2385 - accuracy: 0.5307 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.2308 - accuracy: 0.5312 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.2308 - accuracy: 0.5312 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.2308 - accuracy: 0.5312 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.2308 - accuracy: 0.5312 - val_loss: 8.1799 - val_accuracy: 0.4697 - 33ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_47 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 6.2024 - accuracy: 0.5218 - val_loss: 8.1799 - val_accuracy: 0.4697 - 539ms/epoch - 77ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_48 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 6.3396 - accuracy: 0.4987 - val_loss: 8.1799 - val_accuracy: 0.4697 - 533ms/epoch - 76ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 29ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_49 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 6.8437 - accuracy: 0.4739 - val_loss: 7.2116 - val_accuracy: 0.5273 - 544ms/epoch - 78ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 7.9256 - accuracy: 0.4807 - val_loss: 7.2121 - val_accuracy: 0.5273 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 7.9470 - accuracy: 0.4797 - val_loss: 7.1967 - val_accuracy: 0.5283 - 29ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 7.9032 - accuracy: 0.4827 - val_loss: 7.9904 - val_accuracy: 0.4808 - 32ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 7.4975 - accuracy: 0.5127 - val_loss: 7.8700 - val_accuracy: 0.4889 - 31ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 7.3408 - accuracy: 0.5231 - val_loss: 7.9541 - val_accuracy: 0.4828 - 30ms/epoch - 4ms/step\n",
      "Epoch 7/80\n",
      "7/7 - 0s - loss: 7.3451 - accuracy: 0.5228 - val_loss: 8.0575 - val_accuracy: 0.4768 - 31ms/epoch - 4ms/step\n",
      "Epoch 8/80\n",
      "7/7 - 0s - loss: 7.3419 - accuracy: 0.5231 - val_loss: 8.0579 - val_accuracy: 0.4768 - 40ms/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 1.3952 - accuracy: 0.4934 - val_loss: 1.5315 - val_accuracy: 0.4495 - 541ms/epoch - 42ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 0.7345 - accuracy: 0.5398 - val_loss: 0.9460 - val_accuracy: 0.5061 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 0.7363 - accuracy: 0.5457 - val_loss: 0.8010 - val_accuracy: 0.4919 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 0.7180 - accuracy: 0.5239 - val_loss: 0.7782 - val_accuracy: 0.4990 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 0.6784 - accuracy: 0.5906 - val_loss: 0.9599 - val_accuracy: 0.5051 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 0.6887 - accuracy: 0.5706 - val_loss: 0.7798 - val_accuracy: 0.5141 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 0.7067 - accuracy: 0.5766 - val_loss: 0.8591 - val_accuracy: 0.5020 - 43ms/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "13/13 - 0s - loss: 0.6972 - accuracy: 0.5858 - val_loss: 1.0070 - val_accuracy: 0.4475 - 44ms/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "13/13 - 0s - loss: 0.7090 - accuracy: 0.5754 - val_loss: 1.0157 - val_accuracy: 0.4949 - 45ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_51 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 1.3488 - accuracy: 0.4970 - val_loss: 1.3685 - val_accuracy: 0.5192 - 560ms/epoch - 43ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 0.8149 - accuracy: 0.5071 - val_loss: 0.7917 - val_accuracy: 0.4990 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 0.7264 - accuracy: 0.5464 - val_loss: 0.8069 - val_accuracy: 0.4747 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 0.7070 - accuracy: 0.5236 - val_loss: 0.8037 - val_accuracy: 0.4818 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 0.6796 - accuracy: 0.5668 - val_loss: 0.7325 - val_accuracy: 0.5283 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 0.6768 - accuracy: 0.5805 - val_loss: 0.8351 - val_accuracy: 0.4960 - 45ms/epoch - 3ms/step\n",
      "Epoch 7/60\n",
      "13/13 - 0s - loss: 0.6782 - accuracy: 0.5779 - val_loss: 0.7530 - val_accuracy: 0.5343 - 44ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "13/13 - 0s - loss: 0.6726 - accuracy: 0.5939 - val_loss: 1.0065 - val_accuracy: 0.4848 - 39ms/epoch - 3ms/step\n",
      "Epoch 9/60\n",
      "13/13 - 0s - loss: 0.6787 - accuracy: 0.5721 - val_loss: 0.8185 - val_accuracy: 0.5101 - 41ms/epoch - 3ms/step\n",
      "Epoch 10/60\n",
      "13/13 - 0s - loss: 0.7317 - accuracy: 0.5904 - val_loss: 1.4534 - val_accuracy: 0.4606 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_52 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 1.1569 - accuracy: 0.5074 - val_loss: 0.8086 - val_accuracy: 0.5545 - 536ms/epoch - 41ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 0.7695 - accuracy: 0.5157 - val_loss: 0.7433 - val_accuracy: 0.4970 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 0.7129 - accuracy: 0.5429 - val_loss: 0.7660 - val_accuracy: 0.4727 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 0.7062 - accuracy: 0.5503 - val_loss: 0.7563 - val_accuracy: 0.4646 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 0.6849 - accuracy: 0.5820 - val_loss: 0.7670 - val_accuracy: 0.4657 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 0.6797 - accuracy: 0.5777 - val_loss: 1.0896 - val_accuracy: 0.5000 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/70\n",
      "13/13 - 0s - loss: 0.6991 - accuracy: 0.5614 - val_loss: 0.7656 - val_accuracy: 0.4859 - 44ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_53 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 1.2551 - accuracy: 0.5135 - val_loss: 0.8557 - val_accuracy: 0.4859 - 850ms/epoch - 65ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 0.7758 - accuracy: 0.5254 - val_loss: 0.8221 - val_accuracy: 0.5192 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 0.7197 - accuracy: 0.5330 - val_loss: 0.9133 - val_accuracy: 0.4899 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 0.7200 - accuracy: 0.5325 - val_loss: 0.8070 - val_accuracy: 0.5152 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 0.6813 - accuracy: 0.5584 - val_loss: 0.8169 - val_accuracy: 0.5000 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 0.6733 - accuracy: 0.5789 - val_loss: 0.8850 - val_accuracy: 0.5232 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 0.6675 - accuracy: 0.5876 - val_loss: 0.9771 - val_accuracy: 0.5182 - 41ms/epoch - 3ms/step\n",
      "Epoch 8/80\n",
      "13/13 - 0s - loss: 0.6948 - accuracy: 0.5629 - val_loss: 1.0380 - val_accuracy: 0.4828 - 42ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "13/13 - 0s - loss: 0.6889 - accuracy: 0.5698 - val_loss: 0.8609 - val_accuracy: 0.4626 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 6.7322 - accuracy: 0.5236 - val_loss: 8.1799 - val_accuracy: 0.4697 - 563ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_55 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.7176 - accuracy: 0.4678 - val_loss: 7.1625 - val_accuracy: 0.5303 - 536ms/epoch - 41ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_56 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.7923 - accuracy: 0.5150 - val_loss: 7.4871 - val_accuracy: 0.5101 - 553ms/epoch - 43ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.9932 - accuracy: 0.4766 - val_loss: 7.3488 - val_accuracy: 0.5192 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.9525 - accuracy: 0.4794 - val_loss: 7.3332 - val_accuracy: 0.5202 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.9486 - accuracy: 0.4797 - val_loss: 7.3488 - val_accuracy: 0.5192 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.9487 - accuracy: 0.4797 - val_loss: 7.3488 - val_accuracy: 0.5192 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.9487 - accuracy: 0.4797 - val_loss: 7.3488 - val_accuracy: 0.5192 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/70\n",
      "13/13 - 0s - loss: 7.9487 - accuracy: 0.4797 - val_loss: 7.3488 - val_accuracy: 0.5192 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/70\n",
      "13/13 - 0s - loss: 7.9487 - accuracy: 0.4797 - val_loss: 7.3488 - val_accuracy: 0.5192 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_57 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 7.4052 - accuracy: 0.4741 - val_loss: 7.4112 - val_accuracy: 0.5152 - 568ms/epoch - 44ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.9223 - accuracy: 0.4810 - val_loss: 7.4127 - val_accuracy: 0.5152 - 41ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.9031 - accuracy: 0.4822 - val_loss: 7.4287 - val_accuracy: 0.5141 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.8727 - accuracy: 0.4840 - val_loss: 7.3370 - val_accuracy: 0.5202 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.8633 - accuracy: 0.4850 - val_loss: 7.3379 - val_accuracy: 0.5202 - 41ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.8980 - accuracy: 0.4827 - val_loss: 7.2909 - val_accuracy: 0.5232 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 7.8614 - accuracy: 0.4850 - val_loss: 7.4370 - val_accuracy: 0.5131 - 42ms/epoch - 3ms/step\n",
      "Epoch 8/80\n",
      "13/13 - 0s - loss: 7.8760 - accuracy: 0.4840 - val_loss: 7.4752 - val_accuracy: 0.5111 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "13/13 - 0s - loss: 7.9041 - accuracy: 0.4820 - val_loss: 7.4000 - val_accuracy: 0.5162 - 40ms/epoch - 3ms/step\n",
      "Epoch 10/80\n",
      "13/13 - 0s - loss: 7.8929 - accuracy: 0.4830 - val_loss: 7.3426 - val_accuracy: 0.5202 - 41ms/epoch - 3ms/step\n",
      "Epoch 11/80\n",
      "13/13 - 0s - loss: 7.9406 - accuracy: 0.4799 - val_loss: 7.3745 - val_accuracy: 0.5182 - 43ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_58 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 7.5464 - accuracy: 0.4685 - val_loss: 7.1625 - val_accuracy: 0.5303 - 559ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 44ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_59 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 6.8294 - accuracy: 0.5201 - val_loss: 8.1799 - val_accuracy: 0.4697 - 554ms/epoch - 43ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_60 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.6538 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 538ms/epoch - 41ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_61 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 7.4335 - accuracy: 0.4820 - val_loss: 7.2280 - val_accuracy: 0.5263 - 576ms/epoch - 44ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.9336 - accuracy: 0.4810 - val_loss: 7.1257 - val_accuracy: 0.5333 - 42ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 8.0567 - accuracy: 0.4739 - val_loss: 7.3472 - val_accuracy: 0.5192 - 42ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 8.0134 - accuracy: 0.4769 - val_loss: 7.4890 - val_accuracy: 0.5101 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 8.0220 - accuracy: 0.4764 - val_loss: 7.4120 - val_accuracy: 0.5152 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.9911 - accuracy: 0.4784 - val_loss: 7.3812 - val_accuracy: 0.5172 - 42ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 7.9951 - accuracy: 0.4782 - val_loss: 7.3968 - val_accuracy: 0.5162 - 41ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_62 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 1.7850 - accuracy: 0.4962 - val_loss: 0.9406 - val_accuracy: 0.4636 - 533ms/epoch - 76ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 0.8137 - accuracy: 0.5109 - val_loss: 0.7974 - val_accuracy: 0.5061 - 32ms/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 0.7563 - accuracy: 0.5178 - val_loss: 0.8134 - val_accuracy: 0.4879 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 0.7135 - accuracy: 0.5294 - val_loss: 0.7634 - val_accuracy: 0.5192 - 34ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 0.6801 - accuracy: 0.5713 - val_loss: 0.7965 - val_accuracy: 0.4929 - 36ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 0.6717 - accuracy: 0.5642 - val_loss: 0.7677 - val_accuracy: 0.5091 - 36ms/epoch - 5ms/step\n",
      "Epoch 7/50\n",
      "7/7 - 0s - loss: 0.6600 - accuracy: 0.6076 - val_loss: 0.8042 - val_accuracy: 0.5141 - 36ms/epoch - 5ms/step\n",
      "Epoch 8/50\n",
      "7/7 - 0s - loss: 0.6446 - accuracy: 0.6094 - val_loss: 0.9322 - val_accuracy: 0.4707 - 35ms/epoch - 5ms/step\n",
      "Epoch 9/50\n",
      "7/7 - 0s - loss: 0.6609 - accuracy: 0.6033 - val_loss: 0.8495 - val_accuracy: 0.5020 - 37ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_63 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 1.7580 - accuracy: 0.4957 - val_loss: 0.9215 - val_accuracy: 0.5182 - 555ms/epoch - 79ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 0.8614 - accuracy: 0.4888 - val_loss: 1.4638 - val_accuracy: 0.5374 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 0.8024 - accuracy: 0.5150 - val_loss: 0.8588 - val_accuracy: 0.4606 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 0.7246 - accuracy: 0.5345 - val_loss: 0.9111 - val_accuracy: 0.4758 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 0.7045 - accuracy: 0.5548 - val_loss: 0.8137 - val_accuracy: 0.5030 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 0.6871 - accuracy: 0.5822 - val_loss: 0.8377 - val_accuracy: 0.4737 - 36ms/epoch - 5ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 0.6770 - accuracy: 0.5799 - val_loss: 0.7622 - val_accuracy: 0.4707 - 33ms/epoch - 5ms/step\n",
      "Epoch 8/60\n",
      "7/7 - 0s - loss: 0.6574 - accuracy: 0.6053 - val_loss: 0.7658 - val_accuracy: 0.5051 - 32ms/epoch - 5ms/step\n",
      "Epoch 9/60\n",
      "7/7 - 0s - loss: 0.6591 - accuracy: 0.6069 - val_loss: 0.8433 - val_accuracy: 0.4747 - 34ms/epoch - 5ms/step\n",
      "Epoch 10/60\n",
      "7/7 - 0s - loss: 0.6519 - accuracy: 0.6147 - val_loss: 0.9302 - val_accuracy: 0.4768 - 33ms/epoch - 5ms/step\n",
      "Epoch 11/60\n",
      "7/7 - 0s - loss: 0.6469 - accuracy: 0.6239 - val_loss: 0.8913 - val_accuracy: 0.4788 - 34ms/epoch - 5ms/step\n",
      "Epoch 12/60\n",
      "7/7 - 0s - loss: 0.6447 - accuracy: 0.6023 - val_loss: 0.9273 - val_accuracy: 0.4838 - 35ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_64 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 2.0845 - accuracy: 0.5109 - val_loss: 2.9626 - val_accuracy: 0.4727 - 551ms/epoch - 79ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 0.9435 - accuracy: 0.5188 - val_loss: 1.4948 - val_accuracy: 0.5394 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 0.8030 - accuracy: 0.5228 - val_loss: 0.8309 - val_accuracy: 0.5101 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 0.7614 - accuracy: 0.5381 - val_loss: 0.8110 - val_accuracy: 0.5040 - 34ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 0.6995 - accuracy: 0.5599 - val_loss: 0.7806 - val_accuracy: 0.5172 - 37ms/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 0.6693 - accuracy: 0.5784 - val_loss: 0.8279 - val_accuracy: 0.4879 - 38ms/epoch - 5ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 0.6649 - accuracy: 0.5825 - val_loss: 0.7757 - val_accuracy: 0.5040 - 37ms/epoch - 5ms/step\n",
      "Epoch 8/70\n",
      "7/7 - 0s - loss: 0.6445 - accuracy: 0.6221 - val_loss: 0.8736 - val_accuracy: 0.4677 - 36ms/epoch - 5ms/step\n",
      "Epoch 9/70\n",
      "7/7 - 0s - loss: 0.6429 - accuracy: 0.6155 - val_loss: 0.8402 - val_accuracy: 0.5081 - 38ms/epoch - 5ms/step\n",
      "Epoch 10/70\n",
      "7/7 - 0s - loss: 0.6346 - accuracy: 0.6239 - val_loss: 0.8115 - val_accuracy: 0.5192 - 36ms/epoch - 5ms/step\n",
      "Epoch 11/70\n",
      "7/7 - 0s - loss: 0.6547 - accuracy: 0.6048 - val_loss: 0.8489 - val_accuracy: 0.5394 - 36ms/epoch - 5ms/step\n",
      "Epoch 12/70\n",
      "7/7 - 0s - loss: 0.6321 - accuracy: 0.6454 - val_loss: 1.0182 - val_accuracy: 0.5222 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_65 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 1.5996 - accuracy: 0.5137 - val_loss: 0.7873 - val_accuracy: 0.5101 - 530ms/epoch - 76ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 0.7616 - accuracy: 0.4980 - val_loss: 0.8769 - val_accuracy: 0.4970 - 32ms/epoch - 5ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 0.7575 - accuracy: 0.5277 - val_loss: 0.7860 - val_accuracy: 0.4788 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 0.6967 - accuracy: 0.5571 - val_loss: 0.7546 - val_accuracy: 0.4859 - 36ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 0.7075 - accuracy: 0.5505 - val_loss: 0.8892 - val_accuracy: 0.4778 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 0.7128 - accuracy: 0.5612 - val_loss: 0.9151 - val_accuracy: 0.4636 - 36ms/epoch - 5ms/step\n",
      "Epoch 7/80\n",
      "7/7 - 0s - loss: 0.6881 - accuracy: 0.5843 - val_loss: 0.8142 - val_accuracy: 0.4909 - 42ms/epoch - 6ms/step\n",
      "Epoch 8/80\n",
      "7/7 - 0s - loss: 0.6609 - accuracy: 0.6084 - val_loss: 0.8367 - val_accuracy: 0.4889 - 46ms/epoch - 7ms/step\n",
      "Epoch 9/80\n",
      "7/7 - 0s - loss: 0.6644 - accuracy: 0.6051 - val_loss: 0.7855 - val_accuracy: 0.4808 - 37ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_66 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.6877 - accuracy: 0.4909 - val_loss: 7.6686 - val_accuracy: 0.5010 - 548ms/epoch - 78ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.2443 - accuracy: 0.5294 - val_loss: 7.9077 - val_accuracy: 0.4869 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.2665 - accuracy: 0.5284 - val_loss: 7.8920 - val_accuracy: 0.4879 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.2705 - accuracy: 0.5282 - val_loss: 7.8764 - val_accuracy: 0.4889 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.2744 - accuracy: 0.5279 - val_loss: 7.8764 - val_accuracy: 0.4889 - 34ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.2706 - accuracy: 0.5282 - val_loss: 7.8764 - val_accuracy: 0.4889 - 34ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_67 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 6.3105 - accuracy: 0.5327 - val_loss: 8.0669 - val_accuracy: 0.4768 - 534ms/epoch - 76ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.2060 - accuracy: 0.5327 - val_loss: 7.9568 - val_accuracy: 0.4838 - 34ms/epoch - 5ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.2066 - accuracy: 0.5325 - val_loss: 8.0193 - val_accuracy: 0.4798 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.2010 - accuracy: 0.5330 - val_loss: 8.0879 - val_accuracy: 0.4747 - 37ms/epoch - 5ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.1992 - accuracy: 0.5332 - val_loss: 8.1464 - val_accuracy: 0.4717 - 36ms/epoch - 5ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.1877 - accuracy: 0.5340 - val_loss: 8.1322 - val_accuracy: 0.4727 - 35ms/epoch - 5ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 7.1880 - accuracy: 0.5338 - val_loss: 8.0729 - val_accuracy: 0.4758 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_68 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 6.3023 - accuracy: 0.5081 - val_loss: 8.1799 - val_accuracy: 0.4697 - 925ms/epoch - 132ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_69 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 7.1025 - accuracy: 0.4594 - val_loss: 7.1625 - val_accuracy: 0.5303 - 561ms/epoch - 80ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 33ms/epoch - 5ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_70 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.2806 - accuracy: 0.5183 - val_loss: 8.1799 - val_accuracy: 0.4697 - 530ms/epoch - 76ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_71 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 6.2011 - accuracy: 0.5246 - val_loss: 8.1799 - val_accuracy: 0.4697 - 561ms/epoch - 80ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 32ms/epoch - 5ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_72 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 6.2217 - accuracy: 0.5147 - val_loss: 8.1799 - val_accuracy: 0.4697 - 538ms/epoch - 77ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 30ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 34ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_73 (LSTM)              (None, 5, 70)             27440     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 5, 1)              71        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27511 (107.46 KB)\n",
      "Trainable params: 27511 (107.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 7.1769 - accuracy: 0.4647 - val_loss: 7.1937 - val_accuracy: 0.5283 - 535ms/epoch - 76ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 8.0852 - accuracy: 0.4698 - val_loss: 7.1937 - val_accuracy: 0.5283 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 8.0892 - accuracy: 0.4695 - val_loss: 7.1937 - val_accuracy: 0.5283 - 31ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 8.0853 - accuracy: 0.4698 - val_loss: 7.1781 - val_accuracy: 0.5293 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 8.0892 - accuracy: 0.4695 - val_loss: 7.1781 - val_accuracy: 0.5293 - 34ms/epoch - 5ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 8.0892 - accuracy: 0.4695 - val_loss: 7.1781 - val_accuracy: 0.5293 - 34ms/epoch - 5ms/step\n",
      "Epoch 7/80\n",
      "7/7 - 0s - loss: 8.0892 - accuracy: 0.4695 - val_loss: 7.1781 - val_accuracy: 0.5293 - 31ms/epoch - 4ms/step\n",
      "Epoch 8/80\n",
      "7/7 - 0s - loss: 8.0892 - accuracy: 0.4695 - val_loss: 7.1781 - val_accuracy: 0.5293 - 34ms/epoch - 5ms/step\n",
      "Epoch 9/80\n",
      "7/7 - 0s - loss: 8.0931 - accuracy: 0.4693 - val_loss: 7.1781 - val_accuracy: 0.5293 - 34ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_74 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 1.5281 - accuracy: 0.5127 - val_loss: 0.7952 - val_accuracy: 0.5253 - 549ms/epoch - 42ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 0.7508 - accuracy: 0.5330 - val_loss: 0.7444 - val_accuracy: 0.5172 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 0.7280 - accuracy: 0.5266 - val_loss: 0.7857 - val_accuracy: 0.4838 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 0.7099 - accuracy: 0.5612 - val_loss: 0.9078 - val_accuracy: 0.5030 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 0.7103 - accuracy: 0.5470 - val_loss: 0.8149 - val_accuracy: 0.5192 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 0.6706 - accuracy: 0.5924 - val_loss: 0.7974 - val_accuracy: 0.5020 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "13/13 - 0s - loss: 0.6886 - accuracy: 0.5812 - val_loss: 0.8584 - val_accuracy: 0.4949 - 46ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_75 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 1.5296 - accuracy: 0.5096 - val_loss: 0.9075 - val_accuracy: 0.4899 - 553ms/epoch - 43ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 0.7770 - accuracy: 0.5231 - val_loss: 0.7667 - val_accuracy: 0.5020 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 0.7124 - accuracy: 0.5162 - val_loss: 0.7411 - val_accuracy: 0.4828 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 0.7011 - accuracy: 0.5528 - val_loss: 0.8377 - val_accuracy: 0.4717 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 0.7045 - accuracy: 0.5470 - val_loss: 0.7815 - val_accuracy: 0.4586 - 46ms/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 0.6891 - accuracy: 0.5731 - val_loss: 0.9065 - val_accuracy: 0.4747 - 47ms/epoch - 4ms/step\n",
      "Epoch 7/60\n",
      "13/13 - 0s - loss: 0.6992 - accuracy: 0.5670 - val_loss: 0.9259 - val_accuracy: 0.4737 - 44ms/epoch - 3ms/step\n",
      "Epoch 8/60\n",
      "13/13 - 0s - loss: 0.6965 - accuracy: 0.5647 - val_loss: 0.8904 - val_accuracy: 0.4828 - 59ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_76 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 2.4559 - accuracy: 0.5058 - val_loss: 0.8563 - val_accuracy: 0.4687 - 545ms/epoch - 42ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 0.8368 - accuracy: 0.5041 - val_loss: 0.8967 - val_accuracy: 0.5303 - 43ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 0.7945 - accuracy: 0.5157 - val_loss: 0.7713 - val_accuracy: 0.5091 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 0.7031 - accuracy: 0.5353 - val_loss: 0.8372 - val_accuracy: 0.5101 - 46ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 0.6829 - accuracy: 0.5736 - val_loss: 0.8172 - val_accuracy: 0.5000 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 0.6697 - accuracy: 0.5878 - val_loss: 0.9019 - val_accuracy: 0.5232 - 43ms/epoch - 3ms/step\n",
      "Epoch 7/70\n",
      "13/13 - 0s - loss: 0.6937 - accuracy: 0.5728 - val_loss: 0.7900 - val_accuracy: 0.4939 - 44ms/epoch - 3ms/step\n",
      "Epoch 8/70\n",
      "13/13 - 0s - loss: 0.6831 - accuracy: 0.5518 - val_loss: 0.7740 - val_accuracy: 0.5020 - 42ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_77 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 1.2668 - accuracy: 0.5348 - val_loss: 0.9634 - val_accuracy: 0.5020 - 537ms/epoch - 41ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 0.7910 - accuracy: 0.5119 - val_loss: 0.9212 - val_accuracy: 0.5535 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 0.7234 - accuracy: 0.5411 - val_loss: 0.7933 - val_accuracy: 0.4929 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 0.6864 - accuracy: 0.5599 - val_loss: 0.7726 - val_accuracy: 0.5010 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 0.6770 - accuracy: 0.5685 - val_loss: 0.7998 - val_accuracy: 0.4939 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 0.6671 - accuracy: 0.5774 - val_loss: 1.2510 - val_accuracy: 0.4566 - 44ms/epoch - 3ms/step\n",
      "Epoch 7/80\n",
      "13/13 - 0s - loss: 0.6982 - accuracy: 0.5698 - val_loss: 0.8302 - val_accuracy: 0.4869 - 45ms/epoch - 3ms/step\n",
      "Epoch 8/80\n",
      "13/13 - 0s - loss: 0.6837 - accuracy: 0.5970 - val_loss: 0.9697 - val_accuracy: 0.4990 - 41ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "13/13 - 0s - loss: 0.6884 - accuracy: 0.5878 - val_loss: 1.0054 - val_accuracy: 0.4768 - 44ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_78 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 6.7712 - accuracy: 0.5244 - val_loss: 8.1799 - val_accuracy: 0.4697 - 561ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_79 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 7.6983 - accuracy: 0.4556 - val_loss: 7.1625 - val_accuracy: 0.5303 - 539ms/epoch - 41ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 43ms/epoch - 3ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 44ms/epoch - 3ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 44ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 45ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_80 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.6726 - accuracy: 0.5345 - val_loss: 8.1799 - val_accuracy: 0.4697 - 564ms/epoch - 43ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_81 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 6.7324 - accuracy: 0.5231 - val_loss: 8.1799 - val_accuracy: 0.4697 - 558ms/epoch - 43ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 44ms/epoch - 3ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 58ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 50ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 45ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_82 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "13/13 - 1s - loss: 6.6538 - accuracy: 0.5312 - val_loss: 8.1799 - val_accuracy: 0.4697 - 553ms/epoch - 43ms/step\n",
      "Epoch 2/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 50ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_83 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "13/13 - 1s - loss: 6.6761 - accuracy: 0.5320 - val_loss: 8.1799 - val_accuracy: 0.4697 - 569ms/epoch - 44ms/step\n",
      "Epoch 2/60\n",
      "13/13 - 0s - loss: 7.2270 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "13/13 - 0s - loss: 7.2270 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "13/13 - 0s - loss: 7.2270 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "13/13 - 0s - loss: 7.2270 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 43ms/epoch - 3ms/step\n",
      "Epoch 6/60\n",
      "13/13 - 0s - loss: 7.2270 - accuracy: 0.5315 - val_loss: 8.1799 - val_accuracy: 0.4697 - 46ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_84 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "13/13 - 1s - loss: 6.7125 - accuracy: 0.5272 - val_loss: 8.1799 - val_accuracy: 0.4697 - 572ms/epoch - 44ms/step\n",
      "Epoch 2/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 47ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n",
      "Epoch 4/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n",
      "Epoch 5/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "13/13 - 0s - loss: 7.2231 - accuracy: 0.5317 - val_loss: 8.1799 - val_accuracy: 0.4697 - 48ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_85 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "13/13 - 1s - loss: 7.6058 - accuracy: 0.4632 - val_loss: 7.3168 - val_accuracy: 0.5212 - 1s/epoch - 87ms/step\n",
      "Epoch 2/80\n",
      "13/13 - 0s - loss: 8.0708 - accuracy: 0.4711 - val_loss: 7.3798 - val_accuracy: 0.5172 - 48ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "13/13 - 0s - loss: 8.0285 - accuracy: 0.4736 - val_loss: 7.3648 - val_accuracy: 0.5182 - 47ms/epoch - 4ms/step\n",
      "Epoch 4/80\n",
      "13/13 - 0s - loss: 8.0055 - accuracy: 0.4754 - val_loss: 7.3501 - val_accuracy: 0.5192 - 47ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "13/13 - 0s - loss: 7.9906 - accuracy: 0.4764 - val_loss: 7.3347 - val_accuracy: 0.5202 - 47ms/epoch - 4ms/step\n",
      "Epoch 6/80\n",
      "13/13 - 0s - loss: 7.9833 - accuracy: 0.4769 - val_loss: 7.4443 - val_accuracy: 0.5131 - 47ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_86 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 2.2443 - accuracy: 0.5170 - val_loss: 0.8694 - val_accuracy: 0.4616 - 565ms/epoch - 81ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 0.8415 - accuracy: 0.5165 - val_loss: 0.8519 - val_accuracy: 0.4798 - 34ms/epoch - 5ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 0.7552 - accuracy: 0.5107 - val_loss: 0.8680 - val_accuracy: 0.4828 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 0.7123 - accuracy: 0.5383 - val_loss: 0.8183 - val_accuracy: 0.4859 - 36ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 0.7086 - accuracy: 0.5589 - val_loss: 0.8937 - val_accuracy: 0.4727 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 0.6765 - accuracy: 0.5901 - val_loss: 0.9491 - val_accuracy: 0.5152 - 37ms/epoch - 5ms/step\n",
      "Epoch 7/50\n",
      "7/7 - 0s - loss: 0.6621 - accuracy: 0.5843 - val_loss: 0.9407 - val_accuracy: 0.4727 - 35ms/epoch - 5ms/step\n",
      "Epoch 8/50\n",
      "7/7 - 0s - loss: 0.6412 - accuracy: 0.6279 - val_loss: 0.9595 - val_accuracy: 0.5061 - 36ms/epoch - 5ms/step\n",
      "Epoch 9/50\n",
      "7/7 - 0s - loss: 0.6625 - accuracy: 0.6033 - val_loss: 1.1944 - val_accuracy: 0.4747 - 35ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_87 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 1.6456 - accuracy: 0.4916 - val_loss: 0.8106 - val_accuracy: 0.4818 - 546ms/epoch - 78ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 0.8086 - accuracy: 0.5180 - val_loss: 1.0486 - val_accuracy: 0.5222 - 33ms/epoch - 5ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 0.7862 - accuracy: 0.5086 - val_loss: 0.8351 - val_accuracy: 0.4939 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 0.7018 - accuracy: 0.5543 - val_loss: 0.9403 - val_accuracy: 0.4697 - 36ms/epoch - 5ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 0.6878 - accuracy: 0.5739 - val_loss: 0.8136 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 0.6593 - accuracy: 0.5906 - val_loss: 0.8096 - val_accuracy: 0.4798 - 38ms/epoch - 5ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 0.6378 - accuracy: 0.6203 - val_loss: 0.8255 - val_accuracy: 0.4869 - 37ms/epoch - 5ms/step\n",
      "Epoch 8/60\n",
      "7/7 - 0s - loss: 0.6245 - accuracy: 0.6266 - val_loss: 0.9566 - val_accuracy: 0.4657 - 35ms/epoch - 5ms/step\n",
      "Epoch 9/60\n",
      "7/7 - 0s - loss: 0.6327 - accuracy: 0.6170 - val_loss: 0.9124 - val_accuracy: 0.4909 - 36ms/epoch - 5ms/step\n",
      "Epoch 10/60\n",
      "7/7 - 0s - loss: 0.6101 - accuracy: 0.6289 - val_loss: 1.0150 - val_accuracy: 0.4889 - 37ms/epoch - 5ms/step\n",
      "Epoch 11/60\n",
      "7/7 - 0s - loss: 0.6225 - accuracy: 0.6378 - val_loss: 0.9308 - val_accuracy: 0.4697 - 37ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_88 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 2.0908 - accuracy: 0.5081 - val_loss: 0.8821 - val_accuracy: 0.4899 - 559ms/epoch - 80ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 0.7881 - accuracy: 0.5251 - val_loss: 1.0374 - val_accuracy: 0.4808 - 32ms/epoch - 5ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 0.7900 - accuracy: 0.5256 - val_loss: 0.8780 - val_accuracy: 0.4909 - 34ms/epoch - 5ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 0.7211 - accuracy: 0.5401 - val_loss: 0.8052 - val_accuracy: 0.4838 - 37ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 0.6995 - accuracy: 0.5520 - val_loss: 0.7899 - val_accuracy: 0.5071 - 38ms/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 0.6888 - accuracy: 0.5721 - val_loss: 0.8251 - val_accuracy: 0.4970 - 36ms/epoch - 5ms/step\n",
      "Epoch 7/70\n",
      "7/7 - 0s - loss: 0.6682 - accuracy: 0.5919 - val_loss: 0.7858 - val_accuracy: 0.5010 - 37ms/epoch - 5ms/step\n",
      "Epoch 8/70\n",
      "7/7 - 0s - loss: 0.6540 - accuracy: 0.6005 - val_loss: 0.8320 - val_accuracy: 0.5071 - 37ms/epoch - 5ms/step\n",
      "Epoch 9/70\n",
      "7/7 - 0s - loss: 0.6478 - accuracy: 0.6216 - val_loss: 1.0231 - val_accuracy: 0.4687 - 35ms/epoch - 5ms/step\n",
      "Epoch 10/70\n",
      "7/7 - 0s - loss: 0.6435 - accuracy: 0.6228 - val_loss: 0.9871 - val_accuracy: 0.4828 - 36ms/epoch - 5ms/step\n",
      "Epoch 11/70\n",
      "7/7 - 0s - loss: 0.6334 - accuracy: 0.6322 - val_loss: 1.3151 - val_accuracy: 0.5081 - 36ms/epoch - 5ms/step\n",
      "Epoch 12/70\n",
      "7/7 - 0s - loss: 0.6451 - accuracy: 0.6414 - val_loss: 1.0361 - val_accuracy: 0.5242 - 38ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_89 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 1.9426 - accuracy: 0.5010 - val_loss: 1.5241 - val_accuracy: 0.5162 - 544ms/epoch - 78ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 0.8156 - accuracy: 0.5234 - val_loss: 1.0775 - val_accuracy: 0.5040 - 34ms/epoch - 5ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 0.7736 - accuracy: 0.5360 - val_loss: 0.9196 - val_accuracy: 0.4909 - 34ms/epoch - 5ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 0.7002 - accuracy: 0.5523 - val_loss: 0.8798 - val_accuracy: 0.5010 - 37ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 0.7009 - accuracy: 0.5642 - val_loss: 0.9439 - val_accuracy: 0.5010 - 37ms/epoch - 5ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 0.6733 - accuracy: 0.5942 - val_loss: 0.9106 - val_accuracy: 0.4778 - 36ms/epoch - 5ms/step\n",
      "Epoch 7/80\n",
      "7/7 - 0s - loss: 0.6785 - accuracy: 0.6058 - val_loss: 1.0341 - val_accuracy: 0.4788 - 37ms/epoch - 5ms/step\n",
      "Epoch 8/80\n",
      "7/7 - 0s - loss: 0.6960 - accuracy: 0.5944 - val_loss: 0.9830 - val_accuracy: 0.4778 - 36ms/epoch - 5ms/step\n",
      "Epoch 9/80\n",
      "7/7 - 0s - loss: 0.6643 - accuracy: 0.6137 - val_loss: 1.0157 - val_accuracy: 0.4606 - 37ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_90 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "7/7 - 1s - loss: 6.7495 - accuracy: 0.4772 - val_loss: 7.4791 - val_accuracy: 0.5111 - 538ms/epoch - 77ms/step\n",
      "Epoch 2/50\n",
      "7/7 - 0s - loss: 7.8989 - accuracy: 0.4838 - val_loss: 7.4836 - val_accuracy: 0.5111 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "7/7 - 0s - loss: 7.7160 - accuracy: 0.4962 - val_loss: 7.7935 - val_accuracy: 0.4919 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "7/7 - 0s - loss: 7.6144 - accuracy: 0.5033 - val_loss: 8.0474 - val_accuracy: 0.4758 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "7/7 - 0s - loss: 7.6363 - accuracy: 0.5020 - val_loss: 7.9103 - val_accuracy: 0.4848 - 36ms/epoch - 5ms/step\n",
      "Epoch 6/50\n",
      "7/7 - 0s - loss: 7.6173 - accuracy: 0.5033 - val_loss: 8.0198 - val_accuracy: 0.4778 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_91 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/60\n",
      "7/7 - 1s - loss: 6.2322 - accuracy: 0.5249 - val_loss: 8.0108 - val_accuracy: 0.4798 - 546ms/epoch - 78ms/step\n",
      "Epoch 2/60\n",
      "7/7 - 0s - loss: 7.3837 - accuracy: 0.5206 - val_loss: 7.9339 - val_accuracy: 0.4848 - 34ms/epoch - 5ms/step\n",
      "Epoch 3/60\n",
      "7/7 - 0s - loss: 7.4778 - accuracy: 0.5145 - val_loss: 7.9341 - val_accuracy: 0.4848 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/60\n",
      "7/7 - 0s - loss: 7.3852 - accuracy: 0.5206 - val_loss: 8.1572 - val_accuracy: 0.4707 - 37ms/epoch - 5ms/step\n",
      "Epoch 5/60\n",
      "7/7 - 0s - loss: 7.3178 - accuracy: 0.5251 - val_loss: 8.1898 - val_accuracy: 0.4687 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/60\n",
      "7/7 - 0s - loss: 7.2937 - accuracy: 0.5266 - val_loss: 8.1751 - val_accuracy: 0.4697 - 38ms/epoch - 5ms/step\n",
      "Epoch 7/60\n",
      "7/7 - 0s - loss: 7.2754 - accuracy: 0.5279 - val_loss: 8.1907 - val_accuracy: 0.4687 - 39ms/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_92 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "7/7 - 1s - loss: 6.1711 - accuracy: 0.5211 - val_loss: 8.1799 - val_accuracy: 0.4697 - 551ms/epoch - 79ms/step\n",
      "Epoch 2/70\n",
      "7/7 - 0s - loss: 7.2298 - accuracy: 0.5310 - val_loss: 8.1799 - val_accuracy: 0.4697 - 31ms/epoch - 4ms/step\n",
      "Epoch 3/70\n",
      "7/7 - 0s - loss: 7.2186 - accuracy: 0.5320 - val_loss: 8.1799 - val_accuracy: 0.4697 - 33ms/epoch - 5ms/step\n",
      "Epoch 4/70\n",
      "7/7 - 0s - loss: 7.2438 - accuracy: 0.5302 - val_loss: 8.1799 - val_accuracy: 0.4697 - 36ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "7/7 - 0s - loss: 7.2001 - accuracy: 0.5330 - val_loss: 8.1799 - val_accuracy: 0.4697 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/70\n",
      "7/7 - 0s - loss: 7.2553 - accuracy: 0.5289 - val_loss: 8.1799 - val_accuracy: 0.4697 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_93 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "7/7 - 1s - loss: 7.0406 - accuracy: 0.4632 - val_loss: 7.1625 - val_accuracy: 0.5303 - 563ms/epoch - 80ms/step\n",
      "Epoch 2/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 32ms/epoch - 5ms/step\n",
      "Epoch 3/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 32ms/epoch - 5ms/step\n",
      "Epoch 4/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 5ms/step\n",
      "Epoch 5/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 35ms/epoch - 5ms/step\n",
      "Epoch 6/80\n",
      "7/7 - 0s - loss: 8.1084 - accuracy: 0.4683 - val_loss: 7.1625 - val_accuracy: 0.5303 - 36ms/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_94 (LSTM)              (None, 5, 80)             34560     \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 5, 1)              81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34641 (135.32 KB)\n",
      "Trainable params: 34641 (135.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1546\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:   \u001b[38;5;66;03m# pytype: disable=wrong-arg-count\u001b[39;00m\n\u001b[0;32m-> 1546\u001b[0m   \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationGetAttrValueProto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1547\u001b[0m   data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'gradient_tape/sequential_95/lstm_94/while/Placeholder_22' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m val_performance \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Check if this configuration is the best so far\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    911\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/__autograph_generated_filexo2yzds3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1381\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     )\n\u001b[1;32m   1383\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1384\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1386\u001b[0m     outputs,\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1388\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1389\u001b[0m )\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/engine/training.py:1373\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1373\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/engine/training.py:1154\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:276\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(var_list):\n\u001b[1;32m    274\u001b[0m             var_list \u001b[38;5;241m=\u001b[39m var_list()\n\u001b[0;32m--> 276\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:148\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:422\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    419\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m counter \u001b[38;5;241m<\u001b[39m forward_loop_iters\n\u001b[1;32m    421\u001b[0m grad_cond_name \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39munique_grad_fn_name(op\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 422\u001b[0m cond_grad_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_cond_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhileCondFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_cond_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m _check_num_inputs_outputs(cond_grad_graph, body_grad_graph, \u001b[38;5;28mlen\u001b[39m(loop_vars))\n\u001b[1;32m    428\u001b[0m outputs \u001b[38;5;241m=\u001b[39m _build_while_op(\n\u001b[1;32m    429\u001b[0m     loop_vars,\n\u001b[1;32m    430\u001b[0m     cond_grad_graph,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m while_op\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    435\u001b[0m     num_original_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(body_grad_graph\u001b[38;5;241m.\u001b[39moutputs))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:987\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    985\u001b[0m   deps_control_manager \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mNullContextmanager()\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default(), deps_control_manager \u001b[38;5;28;01mas\u001b[39;00m deps_ctx:\n\u001b[1;32m    988\u001b[0m   current_scope \u001b[38;5;241m=\u001b[39m variable_scope\u001b[38;5;241m.\u001b[39mget_variable_scope()\n\u001b[1;32m    989\u001b[0m   default_use_resource \u001b[38;5;241m=\u001b[39m current_scope\u001b[38;5;241m.\u001b[39muse_resource\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps.py:459\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    456\u001b[0m resource_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# Check for any resource inputs. If we find any, we update control_inputs\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# and last_write_to_resource.\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inp, resource_type \u001b[38;5;129;01min\u001b[39;00m _get_resource_inputs(op):\n\u001b[1;32m    460\u001b[0m   is_read \u001b[38;5;241m=\u001b[39m resource_type \u001b[38;5;241m==\u001b[39m ResourceType\u001b[38;5;241m.\u001b[39mREAD_ONLY\n\u001b[1;32m    461\u001b[0m   input_id \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mtensor_id(inp)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps.py:608\u001b[0m, in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_resource_inputs\u001b[39m(op):\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m   reads, writes \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_read_write_resource_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m   saturated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    610\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m saturated:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps_utils.py:105\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (reads, writes)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m   read_only_input_indices \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   writes\u001b[38;5;241m.\u001b[39mupdate(t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mresource)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1546\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1545\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:   \u001b[38;5;66;03m# pytype: disable=wrong-arg-count\u001b[39;00m\n\u001b[0;32m-> 1546\u001b[0m     \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationGetAttrValueProto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1547\u001b[0m     data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1549\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "# Model hyperparameters\n",
    "num_layers = [1, 2, 3] # 2, 2, 2, 2\n",
    "layer_sizes = [50, 60, 70, 80] # 50, 60, 80, 70\n",
    "batch_sizes = [64, 128] # 128, 64, 64, 128\n",
    "learning_rates = [0.1, 1.0, 2.0] # 0.1, 1, 2, 0.1\n",
    "epochs = [50, 60, 70, 80] # 50, 60, 50, 80\n",
    "activ_func = 'relu'\n",
    "\n",
    "best_model = None\n",
    "best_performance = 0.0\n",
    "best_weights = 0.0\n",
    "best_hyperparameters = {}\n",
    "count = 0\n",
    "\n",
    "# Iterate over hyperparameter combinations\n",
    "for num_layer in num_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for batch_size in batch_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                for epoch in epochs:\n",
    "                    count += 1\n",
    "                    # Build the LSTM model\n",
    "                    model = Sequential()\n",
    "                    \n",
    "                    # Add the specified number of LSTM layers\n",
    "                    for _ in range(num_layer):\n",
    "                        model.add(LSTM(layer_size, activation=activ_func, input_shape=(5, X_train.shape[-1]), return_sequences=True))\n",
    "                    \n",
    "                    # Flatten if there are multiple LSTM layers\n",
    "                    if num_layer > 1:\n",
    "                        model.add(Flatten())\n",
    "                    \n",
    "                    # Output layer\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "                    \n",
    "                    # Compile the model\n",
    "                    optimizer = Adam(learning_rate=learning_rate)\n",
    "                    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "                    \n",
    "                    # Print model summary\n",
    "                    print(model.summary())\n",
    "                    \n",
    "                    # Train the model\n",
    "                    es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "                    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, validation_split=0.2, callbacks=[es], verbose=2)\n",
    "                    \n",
    "                    val_performance = history.history['val_accuracy'][-1]\n",
    "                    \n",
    "                    # Check if this configuration is the best so far\n",
    "                    if val_performance > best_performance:\n",
    "                        best_performance = val_performance\n",
    "                        best_model = model\n",
    "                        best_hyperparameters = {\n",
    "                            'num_layer': num_layer,\n",
    "                            'layer_size': layer_size,\n",
    "                            'batch_size': batch_size,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'epochs': epoch\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aea0d838-fff0-47ee-b965-c4fb3b0691f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_35 (LSTM)              (None, 5, 60)             21120     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 5, 1)              61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21181 (82.74 KB)\n",
      "Trainable params: 21181 (82.74 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Best Model Accuracy: 0.5363636016845703\n",
      "Best Model Hyperparameters: {'num_layer': 1, 'layer_size': 60, 'batch_size': 64, 'learning_rate': 2.0, 'epochs': 60}\n",
      "Number of Model Iterations: 93\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()\n",
    "print(f'Best Model Accuracy: {best_performance}')\n",
    "print(f'Best Model Hyperparameters: {best_hyperparameters}')\n",
    "print(f'Number of Model Iterations: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d8cf633-9996-4ac9-90b7-f5a9635c2724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 7.0749 - accuracy: 0.5378\n",
      "Model Accuracy 0.5378\n"
     ]
    }
   ],
   "source": [
    "model_acc = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f'Model Accuracy {model_acc[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ccc20-854d-4725-871e-5393f469d671",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. Graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
