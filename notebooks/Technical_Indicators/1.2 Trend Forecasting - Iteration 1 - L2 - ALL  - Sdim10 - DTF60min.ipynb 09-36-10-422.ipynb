{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ceed9e3-7040-47eb-b06e-504fc7b200c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_price = '../../raw_data/pro_btc_60min_price_df_v2.csv'\n",
    "columns_to_keep_price = ['date', 'open', 'high', 'low', 'adj_close', 'volume']\n",
    "columns_to_drop=['open', 'high', 'low', 'adj_close', 'volume']\n",
    "test_size = 0.2\n",
    "window_size_sequence = 10\n",
    "window_size = 10\n",
    "patience=50\n",
    "validation_split=0.2\n",
    "batch_size=64\n",
    "epochs=100\n",
    "verbose = 1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a54f7-1649-499e-a93a-050892287467",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52195c63-2d5b-46ed-9bf9-5085269d781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import pprint\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import F1Score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35089c2e-05dd-449d-8515-a6986abb4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS --- \n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].legend(['Train', 'Val'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Val'], loc='best')\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197d74ce-9545-42f6-b8ed-438870281f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    squeezed_array = np.squeeze(y_true)\n",
    "    \n",
    "    if not title:\n",
    "        title = 'Confusion Matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(squeezed_array, y_pred)\n",
    "    \n",
    "    # Get class labels\n",
    "    classes = unique_labels(squeezed_array, y_pred)\n",
    "\n",
    "    # Create a heatmap using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"Blues\",\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3298fb8-00eb-4b6f-a8cd-a9095e742fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve1(y_true_cls, y_pred_prob):\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true_cls, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd33121b-6b79-4466-827a-6e71f1529136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bitcoin_prices(prices, color_array, start_index=15, end_index=25):\n",
    "    # Ensure that the lengths of prices and color_array match\n",
    "    assert len(prices) == len(color_array), \"Length mismatch between prices and color_array\"\n",
    "    \n",
    "    # Determine the range of indices to plot\n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if end_index is None:\n",
    "        end_index = len(prices)\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot Bitcoin prices within the specified range\n",
    "    ax.plot(range(start_index, end_index), prices[start_index:end_index], label='Bitcoin Prices', color='black', linewidth=2)\n",
    "    \n",
    "    # Set background color based on the color_array within the specified range\n",
    "    for i in range(start_index + 1, min(end_index, len(prices))):\n",
    "        if color_array[i] == 0:\n",
    "            ax.axvspan(i - 1, i, facecolor='green', alpha=0.2)\n",
    "        else:\n",
    "            ax.axvspan(i - 1, i, facecolor='red', alpha=0.2)\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Bitcoin Price')\n",
    "    ax.set_title('Bitcoin Prices with Background Color')\n",
    "    \n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067e2a16-174c-4e98-86b8-cf3dbd6ce7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_by_index(dataset):\n",
    "    \"\"\"\n",
    "    Split a dataset into two parts based on a given index.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: List or NumPy array, the dataset to be split.\n",
    "    - split_index: int, the index at which to split the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - left_part: List or NumPy array, the left part of the split dataset.\n",
    "    - right_part: List or NumPy array, the right part of the split dataset.\n",
    "    \"\"\"\n",
    "    split_index = df_test.index[0]\n",
    "    \n",
    "    # Split the dataset into two parts\n",
    "    left_part = dataset[:split_index]\n",
    "    right_part = dataset[split_index:]\n",
    "\n",
    "    left_part_sequeezed = left_part.squeeze()\n",
    "    right_part_sequeezed = right_part.squeeze()\n",
    "\n",
    "    right_part_sequeezed_removed_first_row = right_part_sequeezed.drop(right_part_sequeezed.index[0])\n",
    "\n",
    "    return left_part_sequeezed, right_part_sequeezed_removed_first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f119f3-1587-455c-a3a8-62b7436dff4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b1ae7b-efac-486f-8078-17d20562347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_price_data(path_price, columns_to_keep_price):\n",
    "    price_data = pd.read_csv(path_price)\n",
    "    price_df = price_data.copy()\n",
    "    price_df = price_df[columns_to_keep_price]\n",
    "    price_df.set_index('date', inplace=True)\n",
    "\n",
    "    return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecdd3ff-c140-4e88-b5a5-100e8ba3f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = import_price_data(path_price, columns_to_keep_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ed668-817d-482d-b12e-cc78ea11e959",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52dc25-358c-4998-8729-5650c30e4103",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. Add Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a2656e-eec6-4704-8662-9839710f20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling_df(price_df):\n",
    "    \"\"\"\n",
    "    Label a DataFrame by creating a new column 'label', set all values to 0 in that column, \n",
    "    set the values to 1 if open price is lower than adjusted close.\n",
    "\n",
    "    Parameters:\n",
    "    - formated_df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: labeled DataFrame.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a new column 'Label' and initialize with 0 (down)\n",
    "    price_df['label'] = 0\n",
    "\n",
    "    # Step 2: Label +1 (up) where 'Open' is lower than 'Adj Close'\n",
    "    price_df.loc[price_df['open'] < price_df['adj_close'], 'label'] = 1\n",
    "\n",
    "    # Step 4: Rename df\n",
    "    labeled_df = price_df\n",
    "\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011be5ff-9273-49f2-846a-a9b6ec1a8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = labeling_df(price_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973df82-7460-4e6a-bf51-d8393d20ed67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. Analyse Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9d1cd0-f0ad-44fe-989f-f95895b48b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bins: 2\n",
      "Number of labels per Bins: label\n",
      "0    31644\n",
      "1    31194\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_bins = labeled_df['label'].nunique()\n",
    "label_counts = labeled_df['label'].value_counts()\n",
    "\n",
    "print(f'Number of Bins: {num_bins}')\n",
    "print(f'Number of labels per Bins: {label_counts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010709a-43e3-455f-91e5-f0680b678997",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7640e5-2aad-4e57-aac2-0145c6be0b07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. MA5 & MA20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8abc6c-e43d-4946-83f8-a196694c10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_averages(df, column_name='adj_close', window_sizes=[5, 20]):\n",
    "    \"\"\"\n",
    "    Add Moving Averages (MA) columns to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which moving averages are calculated.\n",
    "    - window_sizes (list): List of window sizes for moving averages. Default is [5, 20].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added MA columns.\n",
    "    \"\"\"\n",
    "    for window_size in window_sizes:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9dcc74-5b72-4966-a2bb-f2cd1429a172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. BBup & BBdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c58198-94a8-43b5-bb42-a0eb6b4975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bollinger_bands(df, column_name='adj_close', window_size=20, num_std_dev=2):\n",
    "    \"\"\"\n",
    "    Calculate Bollinger Bands for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Bollinger Bands are calculated.\n",
    "    - window_size (int): Window size for the moving average. Default is 20.\n",
    "    - num_std_dev (int): Number of standard deviations for the upper and lower bands. Default is 2.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Bollinger Bands (BB up, BB down).\n",
    "    \"\"\"\n",
    "    # Calculate the rolling mean (middle band)\n",
    "    df['middle_band'] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "    # Calculate the rolling standard deviation\n",
    "    df['std_dev'] = df[column_name].rolling(window=window_size).std()\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    df['bb_up'] = df['middle_band'] + num_std_dev * df['std_dev']\n",
    "    df['bb_down'] = df['middle_band'] - num_std_dev * df['std_dev']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['middle_band', 'std_dev'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31cd49-2ac8-4d18-a2d7-f25a50f572c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c. RDP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e497d444-0f42-45ec-9c9e-201b0d069057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdp(df, column_name='adj_close'):\n",
    "    \"\"\"\n",
    "    Calculate Relative Difference in the Percentage of the price (RDP(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RDP(1) is calculated.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RDP(1).\n",
    "    \"\"\"\n",
    "    # Calculate RDP(1)\n",
    "    df['rdp_1'] = df[column_name].pct_change() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa69c10-eb19-4a4c-b166-7acaef040296",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### d. BIAS6, BIAS12, BIAS24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66f76475-ad72-4807-b3b6-77b15c51a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(df, column_name='adj_close', ma_windows=[6, 12, 24]):\n",
    "    \"\"\"\n",
    "    Calculate Bias Ratios (BIAS) for specified moving average windows for a column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which BIAS is calculated.\n",
    "    - ma_windows (list): List of moving average window sizes. Default is [6, 12, 24].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for BIAS(6), BIAS(12), and BIAS(24).\n",
    "    \"\"\"\n",
    "    for window_size in ma_windows:\n",
    "        ma_column_name = f'MA_{window_size}'\n",
    "        bias_column_name = f'BIAS_{window_size}'\n",
    "\n",
    "        # Calculate the moving average\n",
    "        df[ma_column_name] = df[column_name].rolling(window=window_size).mean()\n",
    "\n",
    "        # Calculate BIAS\n",
    "        df[bias_column_name] = ((df[column_name] - df[ma_column_name]) / df[ma_column_name]) * 100\n",
    "\n",
    "        # Drop intermediate columns\n",
    "        df.drop(ma_column_name, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1658d-d4dd-4b43-b3a2-19fcbfaf4138",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### e. RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87483478-0168-463c-81f0-a3e1b46b8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(df, column_name='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate the Relative Strength Index (RSI) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which RSI is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for RSI calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for RSI.\n",
    "    \"\"\"\n",
    "    # Calculate daily price changes\n",
    "    df['price_change'] = df[column_name].diff()\n",
    "\n",
    "    # Calculate the average gain and average loss over the specified window\n",
    "    df['gain'] = df['price_change'].apply(lambda x: x if x > 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "    df['loss'] = -df['price_change'].apply(lambda x: x if x < 0 else 0).rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "    # Calculate relative strength (RS)\n",
    "    df['rs'] = df['gain'] / df['loss']\n",
    "\n",
    "    # Calculate RSI\n",
    "    df['rsi'] = 100 - (100 / (1 + df['rs']))\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_change', 'gain', 'loss', 'rs'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c67704d-12eb-4624-9f12-4533d7b474ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### f. EMA12 & EMA26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a452a92-44b4-4439-a3aa-c60f7dacd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(df, column_name='adj_close', ema_short=12, ema_long=26):\n",
    "    \"\"\"\n",
    "    Calculate Exponential Moving Averages (EMA) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which EMA is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for EMA(12) and EMA(26).\n",
    "    \"\"\"\n",
    "    # Calculate EMA(12)\n",
    "    df['ema_12'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate EMA(26)\n",
    "    df['ema_26'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdddae8-381e-48a0-8144-1e80df8ab3a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### g. MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed8ea659-7a88-4f97-bbcc-ea935732cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(df, column_name='adj_close', ema_short=12, ema_long=26, signal_period=9):\n",
    "    \"\"\"\n",
    "    Calculate Moving Average Convergence Divergence (MACD) and its signal line for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which MACD is calculated. Default is 'Close'.\n",
    "    - ema_short (int): Short-term EMA window size. Default is 12.\n",
    "    - ema_long (int): Long-term EMA window size. Default is 26.\n",
    "    - signal_period (int): Signal line EMA window size. Default is 9.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for MACD, Signal Line, and MACD Histogram.\n",
    "    \"\"\"\n",
    "    # Calculate short-term EMA\n",
    "    df['ema_short'] = df[column_name].ewm(span=ema_short, adjust=False).mean()\n",
    "\n",
    "    # Calculate long-term EMA\n",
    "    df['ema_long'] = df[column_name].ewm(span=ema_long, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Line\n",
    "    df['dif'] = df['ema_short'] - df['ema_long']\n",
    "\n",
    "    # Calculate Signal Line\n",
    "    df['signal_line'] = df['dif'].ewm(span=signal_period, adjust=False).mean()\n",
    "\n",
    "    # Calculate MACD Histogram\n",
    "    df['osc'] = df['dif'] - df['signal_line']\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ema_short', 'ema_long'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c73b4b-0513-4d24-bdf5-4782c840a3e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### h. PSY(12) & PSY(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38793c07-b990-4928-a99c-85c13f711d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psy(df, column_name='adj_close', psy_short=12, psy_long=24):\n",
    "    \"\"\"\n",
    "    Calculate Psychological Line (PSY) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PSY is calculated. Default is 'Close'.\n",
    "    - psy_short (int): Short-term PSY window size. Default is 12.\n",
    "    - psy_long (int): Long-term PSY window size. Default is 24.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for PSY(12) and PSY(24).\n",
    "    \"\"\"\n",
    "    # Calculate the percentage of days where the closing price is higher than the previous day's closing price\n",
    "    df['price_up'] = df[column_name].diff() > 0\n",
    "\n",
    "    # Calculate PSY(12)\n",
    "    df['psy_12'] = df['price_up'].rolling(window=psy_short).mean() * 100\n",
    "\n",
    "    # Calculate PSY(24)\n",
    "    df['psy_24'] = df['price_up'].rolling(window=psy_long).mean() * 100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['price_up'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fd8f1-3956-4ff5-861f-24f09e2ef517",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### i. WMS%R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10a8f8a5-2274-40f0-b4e9-581580c7ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def williams_percent_r(df, high_column='high', low_column='low', adj_close_column='adj_close', window=14):\n",
    "    \"\"\"\n",
    "    Calculate Williams %R for a specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - adj_close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - window (int): Window size for Williams %R calculation. Default is 14.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Williams %R.\n",
    "    \"\"\"\n",
    "    # Calculate highest high and lowest low over the specified window\n",
    "    df['hh'] = df[high_column].rolling(window=window).max()\n",
    "    df['ll'] = df[low_column].rolling(window=window).min()\n",
    "\n",
    "    # Calculate Williams %R\n",
    "    df['williams_%r'] = (df['hh'] - df[adj_close_column]) / (df['hh'] - df['ll']) * -100\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['hh', 'll'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d3132-3f47-45ce-86bc-211eefd49ed0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### j. Stochastic%K & Stochastic%D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84cee4d8-58a8-4d2a-8ab1-1cbcac7cae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_oscillator(df, high_column='high', low_column='low', adj_close_column='adj_close', k_window=14, d_window=3):\n",
    "    \"\"\"\n",
    "    Calculate Stochastic Oscillator (%K and %D) for specified high, low, and close columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - high_column (str): Name of the column containing high prices. Default is 'High'.\n",
    "    - low_column (str): Name of the column containing low prices. Default is 'Low'.\n",
    "    - close_column (str): Name of the column containing close prices. Default is 'Close'.\n",
    "    - k_window (int): Window size for %K calculation. Default is 14.\n",
    "    - d_window (int): Window size for %D calculation. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with added columns for Stochastic %K and %D.\n",
    "    \"\"\"\n",
    "    # Calculate lowest low and highest high over the specified window\n",
    "    df['ll'] = df[low_column].rolling(window=k_window).min()\n",
    "    df['hh'] = df[high_column].rolling(window=k_window).max()\n",
    "\n",
    "    # Calculate Stochastic %K\n",
    "    df['stochastic_%k'] = ((df[adj_close_column] - df['ll']) / (df['hh'] - df['ll'])) * 100\n",
    "\n",
    "    # Calculate Stochastic %D (3-day simple moving average of %K)\n",
    "    df['stochastic_%d'] = df['stochastic_%k'].rolling(window=d_window).mean()\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    df.drop(['ll', 'hh'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b4d5a-b56c-45f9-8310-81d74f203500",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### k. PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "792d0aba-c9c5-4a9f-a205-2adacec2292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Percentage of Price Change (PROC) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which PROC is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for PROC calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for PROC.\n",
    "    \"\"\"\n",
    "    # Calculate the percentage change in price using rolling window\n",
    "    df['proc'] = df[column_name].pct_change().rolling(window=window).mean() * 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f6f19-0063-422a-b839-1a26ce9fc867",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### l. MO1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a192aa-ca41-4cf9-8541-76700666109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(df, column_name='adj_close', window=1):\n",
    "    \"\"\"\n",
    "    Calculate Momentum (MO) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which Momentum is calculated. Default is 'Close'.\n",
    "    - window (int): Window size for Momentum calculation. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Momentum.\n",
    "    \"\"\"\n",
    "    # Calculate the difference in price over the specified window\n",
    "    df['momentum'] = df[column_name].diff(window)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c55f38-3b18-465a-a39e-1d88a3b2551f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### m. LAG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7382320-cff8-417e-9407-286e6f2a45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_lag(df, column_name='adj_close', lag=1):\n",
    "    \"\"\"\n",
    "    Calculate First-Order Lag (LAG(1)) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - column_name (str): Name of the column for which the lag is calculated. Default is 'Close'.\n",
    "    - lag (int): Number of periods to lag. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for the First-Order Lag.\n",
    "    \"\"\"\n",
    "    # Calculate the First-Order Lag using the shift() method\n",
    "    df[f'LAG_{lag}'] = df[column_name].shift(lag)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349313bd-9bb0-4325-81b4-64908947f0d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### n. VOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e5a8d8-019a-4773-b5d9-e16d35fd4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_volume(df, volume_column='volume'):\n",
    "    \"\"\"\n",
    "    Calculate Trading Volume (VOL) for a specified column in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - volume_column (str): Name of the column containing trading volume. Default is 'Volume'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with an added column for Trading Volume.\n",
    "    \"\"\"\n",
    "    df['vol'] = df[volume_column]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9b0e8-3094-4860-9c1b-dedefcf7013b",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fba5c2-2ec3-4d40-8289-09d6a8607c43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### a. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adee4912-bcad-49aa-8149-d5071f751e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(labeled_df):\n",
    "\n",
    "    moving_averages(labeled_df)\n",
    "    bollinger_bands(labeled_df)\n",
    "    rdp(labeled_df)\n",
    "    bias(labeled_df)\n",
    "    rsi(labeled_df)\n",
    "    ema(labeled_df)\n",
    "    macd(labeled_df)\n",
    "    psy(labeled_df)\n",
    "    williams_percent_r(labeled_df)\n",
    "    stochastic_oscillator(labeled_df)\n",
    "    proc(labeled_df)\n",
    "    momentum(labeled_df)\n",
    "    first_order_lag(labeled_df)\n",
    "    trading_volume(labeled_df)\n",
    "\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ca1c510-0dbb-4499-9403-78a155cc97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_features_df = feature_selection(labeled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b141e17-6ca2-4c2e-b064-88691cf21852",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### b. Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cb9d1bf-a0f0-4bbd-b7cb-5637d103703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_df(labeled_features_df, columns_to_drop=['open', 'high', 'low', 'adj_close', 'volume']):\n",
    "    \"\"\"\n",
    "    Drop specified columns from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    - columns_to_drop (list): List of column names to drop. Default is ['Open', 'High', 'Low', 'Adj_Close', 'Volume'].\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with specified columns dropped.\n",
    "    \"\"\"\n",
    "    # Drop specified columns\n",
    "    cleaned_df = labeled_features_df.drop(columns=columns_to_drop, errors='IgnoreRaise')\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    cleaned_df = cleaned_df.dropna()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04ae50fa-6aff-45a8-b746-03afb83aabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df(labeled_features_df, columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b8b0c-9e65-419f-8137-1e0b5931c2ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### c. Standadize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ce085ec-b70a-414d-b508-6514d368d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataframe(cleaned_df):\n",
    "    \"\"\"\n",
    "    Scale a DataFrame using Standard scaling.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Scaled DataFrame.\n",
    "    \"\"\"\n",
    "    # Scale the selected columns\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    index_column = cleaned_df.index\n",
    "    \n",
    "    label_column = cleaned_df['label']\n",
    "    int_df = cleaned_df.drop(columns=['label'])\n",
    "    \n",
    "    columns_to_scale = int_df.columns\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaler.fit_transform(int_df), columns=columns_to_scale)\n",
    "    scaled_df.index = index_column\n",
    "    scaled_df['label'] = label_column\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96848d6c-0545-4721-af91-fe3007fed3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = scale_dataframe(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40832f02-8332-4c86-b8aa-9de12600e3b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### d. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ff886a7-d8d7-4358-ae7b-c2ce24c8dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(scaled_df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split a time series dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df: the input time series dataset.\n",
    "    - test_size (float): the proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "    - df_train, df_test: Pandas arrays, representing features and target values for each set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract index number of splitting points\n",
    "    len_df = len(scaled_df)\n",
    "    index_1 = round(len_df*(1-(test_size)))\n",
    "    index_2 = index_1 +1\n",
    "\n",
    "    # Extract values at previously calculated splitting points\n",
    "    date_1 = scaled_df.index[index_1]\n",
    "    date_2 = scaled_df.index[index_2]\n",
    "\n",
    "    # Construct train_df, val_df and test_df\n",
    "    df_train = scaled_df[:date_1]\n",
    "    df_test = scaled_df[date_2:]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0be47b02-1b21-4e39-8bf7-d459fbf5025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(scaled_df, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb263b-330f-4fab-aafa-66dc4d595753",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### e. Split X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72298675-992b-4536-9492-d47f26a11ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(df, window_size=10):\n",
    "    \"\"\"\n",
    "    Reshape a DataFrames into two 3D NumPy arrays \n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with a list of time series data\n",
    "    - window_size: the number of time steps to consider for each observation\n",
    "\n",
    "    Returns:\n",
    "    - X: (num_observations, window_size, num_features)\n",
    "    - y: (num_observations, num_features_to_predict)\n",
    "    \"\"\"\n",
    "    df_np = df.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    df_X = df.drop('label', axis=1)\n",
    "    df_y = df['label']\n",
    "\n",
    "    for i in range(len(df_np)-(window_size)):\n",
    "        row = df_X[i:i+window_size]\n",
    "        X.append(row)\n",
    "        label = df_y[i+(window_size)]\n",
    "        y.append(label)\n",
    "\n",
    "    # Shift the labels to get the label of the following sequence\n",
    "    y_df_shifted = np.roll(df_y, 1)\n",
    "    \n",
    "    # Drop the first element from X_train_shifted and y_train_shifted\n",
    "    X_df_shifted = df_X[1:]\n",
    "    y_df_shifted = y_df_shifted[1:]\n",
    "\n",
    "    X_df_shifted = np.array(X)\n",
    "    y = np.array(y)\n",
    "    y_df_shifted = np.expand_dims(y, axis=-1)\n",
    "    \n",
    "    return X_df_shifted, y_df_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ecb6e8-8583-4103-84ac-5f824539d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_19899/1185561577.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n",
      "/var/folders/l4/q_79lrcx3ps_z7hltvr9nl4c0000gn/T/ipykernel_19899/1185561577.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = df_y[i+(window_size)]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = split_X_y(df_train, window_size)\n",
    "X_test, y_test = split_X_y(df_test, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b166a45-ad6c-4988-af76-b30a37956385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### f. One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "640b37b7-6530-4dfd-8cb7-5dad20de58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y_train, y_test):\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "    y_train_cat = to_categorical(encoded_y_train)\n",
    "    \n",
    "    encoded_y_test = label_encoder.transform(y_test)\n",
    "    y_test_cat = to_categorical(encoded_y_test)\n",
    "    \n",
    "    return y_train_cat, y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb6465e0-0153-4820-93ff-1c0ffcdd4b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leopolddenassau/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/leopolddenassau/.pyenv/versions/3.10.6/envs/Financial_Trend_Forecasting/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_train_cat, y_test_cat = one_hot_encode(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab396b-e4a8-4ca2-8b05-28b410da38d7",
   "metadata": {},
   "source": [
    "## 11. LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2305dda6-0458-49b2-9145-276be9c30dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_initialization(X_train, window_size=5, loss_function='binary_crossentropy', metrics_list = ['accuracy', F1Score()]):\n",
    "    \n",
    "    #############################\n",
    "    #  1 - Model architecture   #\n",
    "    ############################# \n",
    "    normalizer = Normalization()\n",
    "    normalizer.adapt(X_train)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(normalizer)\n",
    "    model.add(layers.LSTM(units=10, activation='tanh', return_sequences=True, input_shape=(window_size, X_train.shape[-1]), kernel_regularizer=l2(0.5)))\n",
    "    model.add(layers.LSTM(units=3, activation='tanh', return_sequences=False))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    #############################\n",
    "    #  2 - Optimization Method  #\n",
    "    #############################\n",
    "    model.compile(loss= loss_function,\n",
    "                  optimizer = Adam(learning_rate=0.0001), \n",
    "                  metrics = metrics_list) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f8f211b-4292-467d-beca-1a95406eef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_training(model, X_train, y_train, patience=10, validation_split=0.15, batch_size=32, epochs=20, verbose=1):\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_split=validation_split,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs, \n",
    "                        callbacks=[es, reduce_lr],\n",
    "                        verbose=verbose)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fde39ec-4ed5-4537-b1c9-2f8d5e8a71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_validation(model, X_test, y_test, verbose=1):\n",
    "\n",
    "    model_acc = model.evaluate(X_test, y_test, verbose=verbose)\n",
    "\n",
    "    return model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1720e7a-4e81-4525-8036-6e5fb3a195cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, X_test, threshold=0.5):\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    \n",
    "    # Convert predicted probabilities to binary predictions using the threshold\n",
    "    y_pred_binary = (y_pred_probs >= threshold).astype(int)\n",
    "    \n",
    "    # Convert binary predictions to the class labels\n",
    "    y_pred = np.argmax(y_pred_binary, axis=1)\n",
    "\n",
    "    return y_pred_probs, y_pred_binary, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d6311-11fe-4017-91a0-4009b31371d0",
   "metadata": {},
   "source": [
    "## 12. Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8c798-fc3d-41c8-b3a0-f8e0cbf7e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_model_initialization(X_train, window_size)\n",
    "history = lstm_model_training(model, X_train, y_train_cat, patience, validation_split, batch_size, epochs, verbose)\n",
    "model_acc = model_validation(model, X_test, y_test_cat, verbose)\n",
    "y_pred_probs, y_pred_binary, y_pred = model_prediction(model, X_test, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a16f2-717c-448f-9775-f6762421748c",
   "metadata": {},
   "source": [
    "## 13. Train, Val, Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d38bd-fa6d-4cc0-ac1b-b7ae4f3c90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454001f-f799-45d2-bd78-5ec38faa3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'loss train vs val: {history.history[\"loss\"][-1]:.7f} vs {history.history[\"val_loss\"][-1]:.7f}')\n",
    "print(f'accuracy train vs val: {history.history[\"accuracy\"][-1]:.7f} vs {history.history[\"val_accuracy\"][-1]:.7f}')\n",
    "print(f'F1 score train vs val: {history.history[\"f1_score\"][-1]} vs {history.history[\"val_f1_score\"][-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9611d46-530a-43fc-9903-0b64b21f9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edfa138-3d32-4a7d-9027-7b251df457d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The loss on the test set: {model_acc[0]:.7f}')\n",
    "print(f'The accuracy on the test set: {model_acc[1]:.7f}')\n",
    "print(f'The F1 score on the test set: {model_acc[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373658d5-d4f5-4040-ac72-ddac8488c642",
   "metadata": {},
   "source": [
    "## 14. Prediction Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a2818a8-8f7e-45e6-a870-d35a0c81b74a",
   "metadata": {},
   "source": [
    "                     Actual Positive       Actual Negative\n",
    "Predicted Positive   True Positives (TP)  False Positives (FP)\n",
    "Predicted Negative   False Negatives (FN)  True Negatives (TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e2634-ce31-4893-88cd-48a00195e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3249936-0102-4dda-9116-4546a5aa53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve1(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92901f55-6b7b-4733-8b55-bb2e117367d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_part_sequeezed, right_part_sequeezed_removed_first_row = split_dataset_by_index(formated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d7962-6ecf-4264-bf4c-c9fe6c84afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_bitcoin_prices(right_part_sequeezed_removed_first_row, y_pred, start_index=40, end_index=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559887c-0751-4db0-afae-42a0bc19c6f5",
   "metadata": {},
   "source": [
    "## 15. Model Final Test - Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae9d9e-2325-4996-9d0b-e358637989a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../../raw_data/pro_btc_60min_price_unseen_df_v2.csv')\n",
    "df_test = data_test.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
